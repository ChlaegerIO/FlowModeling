{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "# read videos\n",
    "import pylab          # play video\n",
    "from os import listdir\n",
    "# others\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n"
     ]
    }
   ],
   "source": [
    "# read the videos in random order\n",
    "file_names = []\n",
    "for f in listdir('../../Videos/train/'):\n",
    "    file_names.append(f)\n",
    "\n",
    "random.shuffle(file_names)\n",
    "\n",
    "# define transform to tensor and resize to 1080x1920\n",
    "normalize = transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])    # normalize around mean with sigma (std)\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Resize([1080, 1920])])\n",
    "import cv2\n",
    "\n",
    "# read data to list and transform to tensor\n",
    "train_data_tmp = []\n",
    "train_idxOfNewVideo = []\n",
    "count = 0\n",
    "for f in file_names:\n",
    "    if count == 1:\n",
    "        break\n",
    "    count += 1\n",
    "    vidcap = cv2.VideoCapture('../../Videos/train/' + f)\n",
    "    success,image = vidcap.read()\n",
    "    while success:\n",
    "        success,image = vidcap.read()\n",
    "        img_tensor = transform(img)\n",
    "        train_data_tmp.append(img_tensor)\n",
    "    train_idxOfNewVideo.append(len(train_data_tmp))\n",
    "    print(len(train_data_tmp))\n",
    "    print(len(train_data_tmp[0][0][0]), len(train_data_tmp[0][0]), len(train_data_tmp[0])) \n",
    "\n",
    "    \n",
    "## make batches and final train data --> macht das Sinn: train und label sind gleich\n",
    "#train_data = []\n",
    "#batch_size = 128\n",
    "#for i in range(len(train_data_tmp)):\n",
    "#    if i % batch_size == 0:\n",
    "#        train_data.append(torch.stack(train_data_tmp[i-batch_size:i-1]), )\n",
    "#    \n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "   # if len(train_data_list) >= 64:\n",
    "   #     train_data.append(torch.stack(train_data_list), target_label)\n",
    "   #     train_data_list = []\n",
    "   #     break\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920 1080 3\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data_tmp[0][0][0]), len(train_data_tmp[0][0]), len(train_data_tmp[0]))\n",
    "print(torch.min(images), torch.max(images))\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network model\n",
    "d = 3 # number of coordinates for SINDy\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        # N, 3, 1080, 1920\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 5, stride=2, padding=1), # -> N, 16, 539, 959\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 5, stride=2, padding=1), # -> N, 32, 269, 479\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 10, stride=4, padding=2), # -> N, 64, 66, 119\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 9, stride=1, padding=1), # -> N, 128, 60, 113\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 1, 60) # -> N, 1, 1, 52\n",
    "            \n",
    "        )\n",
    "        self.fc1 = nn.Linear(52,d)\n",
    "        self.fc2 = nn.Linear(d, 52)\n",
    "        \n",
    "        # N , 64, 1, 1\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 7), # -> N, 32, 7, 7\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1), # N, 16, 14, 14 (N,16,13,13 without output_padding)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1), # N, 1, 28, 28  (N,1,27,27)\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        encoded = encoded.view(-1,52)\n",
    "        encoded = F.relu(self.fc1(encoded))\n",
    "        \n",
    "        decoded = F.relu(self.fc2(encoded))\n",
    "        decoded = decoded.view(1,1,52)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    "\n",
    "# Note: nn.MaxPool2d -> use nn.MaxUnpool2d, or use different kernelsize, stride etc to compensate...\n",
    "# Input [-1, +1] -> use nn.Tanh\n",
    "model = Autoencoder()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=1e-3, \n",
    "                             weight_decay=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "num_epochs = 1\n",
    "outputs = []\n",
    "for epoch in range(num_epochs):\n",
    "    for (img, _) in data_loader:\n",
    "        # img = img.reshape(-1, 28*28) # -> use for Autoencoder_Linear\n",
    "        recon = model(img)\n",
    "        loss = criterion(recon, img)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch:{epoch+1}, Loss:{loss.item():.4f}')\n",
    "    outputs.append((epoch, img, recon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeatedly reduce the size\n",
    "class Autoencoder_Linear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 128), # (N, 784) -> (N, 128)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 3) # -> N, 3\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 28 * 28),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    "# Input [-1, +1] -> use nn.Tanh\n",
    "\n",
    "# Point to training loop video\n",
    "num_epochs = 1\n",
    "outputs = []\n",
    "for epoch in range(num_epochs):\n",
    "    for (img, _) in data_loader:\n",
    "        # img = img.reshape(-1, 28*28) # -> use for Autoencoder_Linear\n",
    "        recon = model(img)\n",
    "        loss = criterion(recon, img)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch:{epoch+1}, Loss:{loss.item():.4f}')\n",
    "    outputs.append((epoch, img, recon))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
