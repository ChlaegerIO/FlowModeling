{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-18 09:55:26\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "import cv2\n",
    "import random\n",
    "from scipy.signal import savgol_filter\n",
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "import sindy_utils as sindy\n",
    "from datetime import datetime\n",
    "print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "# autoencoder architecture\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__() \n",
    "        self.encode = nn.Sequential(\n",
    "            # encoder: N, 3, 404, 720\n",
    "            nn.Conv2d(3, 16, 2), # N, 16, 403, 719\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 2), # N, 32, 402, 718\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,3), stride=(2,3)), # N, 32, 201, 239              -- pool --\n",
    "            nn.Conv2d(32, 64, 4), # N, 64, 198, 236\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 96, 4), # N, 96, 195, 233\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2), # N, 96, 97, 116                       -- pool --\n",
    "            nn.Conv2d(96, 128, 5), # N, 128, 93, 112\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 150, 5, stride=2, padding=1), # N, 150, 46, 55\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,stride=2), # N, 150, 23, 27                        -- pool --\n",
    "            nn.Conv2d(150, 200, 9, stride=2), # N, 200, 8, 10\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(200*8*10,params['z_dim'])\n",
    "        # Note: nn.MaxPool2d -> use nn.MaxUnpool2d, or use different kernelsize, stride etc to compensate...\n",
    "        # Input [-1, +1] -> use nn.Tanh    \n",
    "        \n",
    "        # note: encoder and decoder are not symmetric\n",
    "        self.decode = nn.Sequential(\n",
    "            nn.ConvTranspose2d(200, 150, 4), # N, 150, 11, 13\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(150, 128, 5, stride=(2,3), padding=(2,2), output_padding=(0,2)), # N, 128, 21, 39\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 96, 4, stride=2, padding=(1,0)), # N, 96, 42, 80\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(96, 64, 8), # N, 64, 49, 87\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 8, stride=2, padding=(2,1), output_padding=(0,1)), # N, 32, 100, 179\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 5, stride=2, padding=1), # N, 16, 201, 359\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 3, 5, stride=2, padding=1, output_padding=(1,1)), # N, 3, 404, 720\n",
    "            nn.ReLU()\n",
    "        )   \n",
    "        \n",
    "        self.fc2 = nn.Linear(params['z_dim'], 200*8*10)\n",
    "\n",
    "    def forward(self, x, z, mode):\n",
    "        '''\n",
    "        x: input for encoder\n",
    "        z: input for decoder\n",
    "        mode: \n",
    "            'train' -> use encoded for decoder\n",
    "            'test'  -> feed z in an get decoded\n",
    "        \n",
    "        '''\n",
    "        if mode == 'train':\n",
    "            encoded = self.encode(x)\n",
    "            encoded = encoded.view(-1,200*8*10)\n",
    "            encoded = self.fc1(encoded)\n",
    "\n",
    "            decoded = self.fc2(encoded)\n",
    "            decoded = decoded.view(-1,200,8,10)\n",
    "            decoded = self.decode(decoded)\n",
    "        else:\n",
    "            encoded = torch.zeros(1)\n",
    "\n",
    "            decoded = self.fc2(z)\n",
    "            decoded = decoded.view(-1,200,8,10)\n",
    "            decoded = self.decode(decoded)\n",
    "        \n",
    "        return encoded, decoded\n",
    "\n",
    "    \n",
    "def calculateSindy(z, Xi, poly_order, include_sine_param):\n",
    "    z_new = z.detach().numpy()\n",
    "    \n",
    "    theta = torch.from_numpy(sindy.sindy_library(z_new, poly_order, include_sine=include_sine_param))\n",
    "    \n",
    "    dz_prediction = torch.matmul(theta, Xi).float()\n",
    "    \n",
    "    return dz_prediction\n",
    "\n",
    "def matrixToNorm(x, offset=0, factor=0.95):\n",
    "    x = (x - x.min() + offset) / x.max() * factor\n",
    "    return x\n",
    "\n",
    "def constructXi(data, zDim):\n",
    "    '''\n",
    "    input: data as a list with shape [len batch_size RGB hight width]\n",
    "    return: Xi for oneVideo training\n",
    "    \n",
    "    '''\n",
    "    # processs the data\n",
    "    z_tensor = torch.empty((0, zDim))\n",
    "    data_len = len(data)\n",
    "    print('length of entire data', data_len)\n",
    "    for i in range(data_len):\n",
    "        if i == 20:\n",
    "            break\n",
    "        z_tensor_tmp, _ = autoencoder(train_data[i], 0, mode='train')\n",
    "        z_tensor = torch.cat((z_tensor, z_tensor_tmp), 0)\n",
    "        if i % 10 == 0:\n",
    "            print(i, z_tensor.shape)\n",
    "        del z_tensor_tmp\n",
    "    \n",
    "    dz_tensor = z_tensor[2:data_len]\n",
    "    z_tensor = z_tensor[1:data_len-1]\n",
    "    \n",
    "    # calculate sindy and Xi for the data\n",
    "    z_tensor = z_tensor.cpu().detach().numpy()\n",
    "    dz_tensor = dz_tensor.cpu().detach().numpy()\n",
    "\n",
    "    Theta = torch.from_numpy(sindy.sindy_library(z_tensor, poly_order, include_sine=include_sine_param))\n",
    "    Xi = torch.from_numpy(sindy.sindy_fit(Theta, dz_tensor, threshold_sindy))\n",
    "    del Theta\n",
    "    del z_tensor\n",
    "    del dz_tensor\n",
    "    \n",
    "    return Xi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data and model loading and configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############################## configurations #####################################\n",
    "poly_order = 4\n",
    "include_sine_param = False\n",
    "threshold_sindy = 0.05\n",
    "\n",
    "# paths\n",
    "path_folder = 'results/v5_6_hyperparam_Ae/'\n",
    "epoch = 1500\n",
    "saveFig = 'figures/v5_6_hyperparam_Ae/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_rate = [1e-05, 0.0001]\n",
    "z_dim = [1,2,3,4,5,10]\n",
    "ae_list = []\n",
    "for lr in lr_rate:\n",
    "    for z in z_dim:\n",
    "        to_load = path_folder+'Ae_'+str(epoch)+'epoch_bs16_lr' + str(lr) +'_z'+ str(z) +'_sindt05_poly4.pt'\n",
    "        ae_list.append(torch.load(to_load).cpu())\n",
    "print('autoencoder', len(ae_list))\n",
    "\n",
    "# load a train data\n",
    "path_folder_data = path_folder+'data/'\n",
    "if os.path.isfile(path_folder_data + 'train_data.pt'):\n",
    "    train_data = torch.load(path_folder_data + 'train_data.pt')\n",
    "    print('train data: ', len(train_data), len(train_data[0]), len(train_data[0][0]), len(train_data[0][0][0]), len(train_data[0][0][0][0]))\n",
    "    print('train data reading done!')\n",
    "\n",
    "if os.path.isfile(path_folder_data + 'validation_data.pt'):\n",
    "    # load a validation data\n",
    "    validation_data = torch.load(path_folder_data + 'validation_data.pt')\n",
    "    print('validation data: ', len(validation_data), len(validation_data[0]), len(validation_data[0][0]), len(validation_data[0][0][0]), len(validation_data[0][0][0][0]))\n",
    "    print('validation data reading done!')\n",
    "\n",
    "if os.path.isfile(path_folder_data + 'test_data.pt'):\n",
    "    # loading test data\n",
    "    test_data = torch.load(path_folder_data + 'test_data.pt')\n",
    "    print('test data: ', len(test_data), len(test_data[0]), len(test_data[0][0]), len(test_data[0][0][0]), len(test_data[0][0][0][0]))\n",
    "    print('test data reading done!')\n",
    "else:\n",
    "    print('No data to read')\n",
    "\n",
    "# load Xi\n",
    "xi_list = []\n",
    "for lr in lr_rate:\n",
    "    for z in z_dim:\n",
    "        if os.path.isfile(path_folder + 'Xi_'+str(epoch+500)+'epoch_bs16_lr' + str(lr) +'_z'+ str(z) +'_sindt05_poly4.pt'):\n",
    "            Xi = torch.load(path_folder + 'Xi_'+str(epoch+500)+'epoch_bs16_lr' + str(lr) +'_z'+ str(z) +'_sindt05_poly4.pt')\n",
    "            xi_list.append(Xi)\n",
    "            print('Xi loaded succesfully!')\n",
    "            print(Xi)\n",
    "        else:\n",
    "            print('No Xi to load')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting images of autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "whichData = 'train_data'      # 1: train_data, 2: validation_data, 3: test_data\n",
    "if whichData == 'train_data':\n",
    "    data = train_data\n",
    "elif whichData == 'validation_data':\n",
    "    data = validation_data\n",
    "else:\n",
    "    data = test_data\n",
    "\n",
    "# compare auto encoder results of different hyperparameters\n",
    "print('random examples')\n",
    "randPlace = random.randint(0, len(data)-1)\n",
    "\n",
    "for lr_i, lr in enumerate(lr_rate):\n",
    "    for z_i, z in enumerate(z_dim):\n",
    "        print('lr',lr,'z dimension',z)\n",
    "        print(lr_i*len(z_dim) + z_i)\n",
    "        autoencoder = ae_list[lr_i*len(z_dim) + z_i]\n",
    "        z_tensor, recon_tensor = autoencoder(data[randPlace], 0, mode='train')\n",
    "        plt.figure()\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(data[randPlace][0].permute(1,2,0).detach().numpy())\n",
    "        plt.subplot(1,2,2)\n",
    "        print('max recon_data', recon_tensor.cpu().detach().numpy().max())\n",
    "        plt.imshow(recon_tensor[0].permute(1,2,0).detach().numpy())\n",
    "        plt.savefig(saveFig + 'autoencoder'+str(epoch)+'Result_lr'+str(lr)+'_z'+str(z)+'_'+whichData+'.png')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate Xi if its not in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Xi for every hyperparameter \n",
    "xi_list = []\n",
    "for lr_i,lr in enumerate(lr_rate):\n",
    "    for z_i,z in enumerate(z_dim):\n",
    "        autoencoder = ae_list[lr_i*len(z_dim) + z_i]\n",
    "        Xi = constructXi(train_data, zDim=z)\n",
    "        torch.save(Xi, path_folder + 'Xi_'+str(epoch)+'epoch_lr'+str(lr)+'_z'+str(z)+'.pt')\n",
    "        xi_list.append(Xi)\n",
    "print('Xi list done!', len(xi_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting in z dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "whichData = 'train_data'      # 1: train_data, 2: validation_data, 3: test_data\n",
    "if whichData == 'train_data':\n",
    "    data = train_data\n",
    "elif whichData == 'validation_data':\n",
    "    data = validation_data\n",
    "else:\n",
    "    data = test_data\n",
    "    \n",
    "ChooseLength = 10  # len(data)\n",
    "batch_size = 16\n",
    "\n",
    "def plotZDim(zDim, lr_rate):\n",
    "    # compute true z\n",
    "    z_true = np.empty((ChooseLength*batch_size, zDim))\n",
    "    for index in range(0, ChooseLength):\n",
    "        if index >= len(data):\n",
    "            break\n",
    "        z_tensor, recon_tensor = autoencoder(data[index], 0, mode='train')\n",
    "        z_true[index*batch_size:(index+1)*batch_size][:] = z_tensor.cpu().detach().numpy()\n",
    "        if index % 5 == 0: print(index)\n",
    "\n",
    "    print('z_true dimension', z_true.shape)\n",
    "\n",
    "    # print graph(s) for z_true\n",
    "    print('graph(s) for z_true')\n",
    "    for graph in range(z_true.shape[1]):\n",
    "        plt.figure(graph)\n",
    "        x = np.linspace(0, z_true.shape[0], z_true.shape[0])\n",
    "        y = z_true[:,graph]\n",
    "        plt.plot(x, y, color='black', label='z true')\n",
    "\n",
    "    # compute sindy z predition based on first one\n",
    "    z_tensor_first, recon_tensor_first = autoencoder(data[0], 0, mode='train')\n",
    "    z = z_tensor_first.cpu().detach().numpy()\n",
    "    z_sindy = np.empty((ChooseLength*batch_size, zDim))\n",
    "    z_sindyUnsmooth = np.empty((ChooseLength*batch_size, zDim))\n",
    "    z_sindy[0:16] = z\n",
    "    for index_s in range(0, ChooseLength-1):\n",
    "        Theta = torch.from_numpy(sindy.sindy_library(z, poly_order, include_sine=include_sine_param))\n",
    "        dz_predict = torch.matmul(Theta, Xi).float()\n",
    "        z_sindy[(index_s+1)*batch_size:(index_s+2)*batch_size] = dz_predict.cpu().detach().numpy()\n",
    "        z = dz_predict\n",
    "\n",
    "\n",
    "    # print graph(s) for z_sindy\n",
    "    print('graph(s) for z_sindy prediction')\n",
    "    for graph in range(z_sindy.shape[1]):\n",
    "        plt.figure(graph)\n",
    "        x = np.linspace(0, z_sindy.shape[0], z_sindy.shape[0])\n",
    "        y = z_sindy[:,graph]\n",
    "        z_sindyUnsmooth[:,graph] = z_sindy[:,graph]              # save unsmoothed signal for later use\n",
    "        plt.plot(x, y, label='z prediction')\n",
    "        # smooth z coordinate plot\n",
    "        z_sindy[:,graph] = savgol_filter(z_sindy[:,graph], 59, 3)\n",
    "        y = z_sindy[:,graph]\n",
    "        plt.plot(x, y, color='red', label='z smoothed')\n",
    "        plt.legend()\n",
    "        plt.savefig(saveFig + 'graph_lr'+str(lr_rate)+'_z'+str(zDim)+'Sindy_train' +str(graph)+ '_'+str(epoch)+'epoch.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return z_sindy\n",
    "        \n",
    "#for lr_i,lr in enumerate(lr_rate):\n",
    "#    for z_i,z in enumerate(z_dim):\n",
    "for lr in [0.0001]:\n",
    "    for z in [3]:\n",
    "        #autoencoder = ae_list[lr_i*len(z_dim) + z_i]\n",
    "        #Xi = xi_list[lr_i*len(z_dim) + z_i]\n",
    "        autoencoder = ae_list[8]\n",
    "        Xi = xi_list[8]\n",
    "        z_sindy = plotZDim(z, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing a video with sindy steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "until = 20\n",
    "\n",
    "# test model\n",
    "def test(data):\n",
    "    video_reconstruction = []\n",
    "    # predict videos\n",
    "    # first step encode first batch\n",
    "    img = data[0]\n",
    "    encode_tensor, recon_tensor = autoencoder(img, 0, mode='train')\n",
    "    \n",
    "    # predict the future using only sindy model, new video starts always at position vid_nbr * until\n",
    "    for i in range(0, until):\n",
    "        if i % 5 == 0: print('pred', i)\n",
    "        video_reconstruction.append(recon_tensor)\n",
    "        dz_tensor = calculateSindy(encode_tensor, Xi, poly_order, include_sine_param)\n",
    "        _, recon_tensor = autoencoder(0, dz_tensor, mode='test')\n",
    "        encode_tensor = dz_tensor\n",
    "            \n",
    "    return video_reconstruction\n",
    "\n",
    "\n",
    "autoencoder = ae_list[8]\n",
    "Xi = xi_list[8]\n",
    "video_output = test(test_data)\n",
    "print('prediction done!')\n",
    "\n",
    "#del test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test with z_sindy from above\n",
    "batch_size = 16\n",
    "\n",
    "# test model with filtered z coordinates\n",
    "def test(zData):\n",
    "    video_reconstruction = []\n",
    "    # predict videos\n",
    "    for i in range(int(len(zData)/batch_size)):\n",
    "        if i % 5 == 0: print('pred', i)\n",
    "        z_tensor = torch.from_numpy(zData[i*batch_size:(i+1)*batch_size,:])\n",
    "        _, recon_tensor = autoencoder(0, z_tensor.float(), mode='test')\n",
    "        video_reconstruction.append(recon_tensor)        \n",
    "            \n",
    "    return video_reconstruction\n",
    "\n",
    "\n",
    "video_output = test(z_sindy)\n",
    "print('prediction done!')\n",
    "\n",
    "#del test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make videos\n",
    "frame_width = len(video_output[0][0][0][0])\n",
    "frame_height = len(video_output[0][0][0])\n",
    "fps = 25.0\n",
    "video_output = video_output\n",
    "#fourcc = cv2.VideoWriter_fourcc('I','4','2','0')\n",
    "#fourcc = cv2.VideoWriter_fourcc('P','I','M','1')\n",
    "#fourcc = cv2.VideoWriter_fourcc('X','V','I','D')\n",
    "fourcc = cv2.VideoWriter_fourcc('D','I','V','3')\n",
    "#fourcc = cv2.VideoWriter_fourcc('F','L','V','1')\n",
    "# write different videos\n",
    "#fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "#fourcc = cv2.VideoWriter_fourcc('D','I','V','3')\n",
    "#fourcc = cv2.VideoWriter_fourcc('F','M','P','4')\n",
    "out1 = cv2.VideoWriter(saveFig +'videoSindyPrediction.avi', fourcc, fps, (frame_width,frame_height))\n",
    "#out2 = cv2.VideoWriter('video2.mov',cv2.VideoWriter_fourcc('M','J','P','G'), fps, (frame_width,frame_height))\n",
    "\n",
    "\n",
    "print('output video', len(video_output), len(video_output[0]), len(video_output[0][0]), len(video_output[0][0][0]), len(video_output[0][0][0][0]))\n",
    "\n",
    "# undo batch structure\n",
    "videoProcessing = []\n",
    "count = -1\n",
    "for img in range(0, len(video_output)*len(video_output[0])):\n",
    "    imgIn_batch = img % batch_size\n",
    "    # new batch\n",
    "    if imgIn_batch == 0:\n",
    "        count += 1\n",
    "    img_toAppend = video_output[count][imgIn_batch]\n",
    "    videoProcessing.append(img_toAppend)\n",
    "        \n",
    "#del video_output\n",
    "print('video currently procession', len(videoProcessing), len(videoProcessing[0]), len(videoProcessing[0][0]), len(videoProcessing[0][0][0]))\n",
    "    \n",
    "for img in range(0,len(videoProcessing)):\n",
    "    frame_local = np.transpose(videoProcessing[img].detach().numpy(), [1,2,0])\n",
    "    frame_local = cv2.cvtColor(frame_local, cv2.COLOR_RGB2BGR)\n",
    "    # print(frame_local) --> seems unstable, not a number and doesn't save it as a video\n",
    "    out1.write(frame_local.shape)\n",
    "    # show video\n",
    "    cv2.imshow('Frame',frame_local)\n",
    "\n",
    "    # wait at the beginning\n",
    "    if img == 0:\n",
    "        print('stopped video in frame',img)\n",
    "        while(True):\n",
    "            if cv2.waitKey(25) & 0xFF == ord('e'):\n",
    "                break   \n",
    "\n",
    "    # Press Q on keyboard to  exit\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q') and img >= 10:\n",
    "        break\n",
    "    \n",
    "    # Press w on keyboard to wait\n",
    "    if cv2.waitKey(25) & 0xFF == ord('w'):\n",
    "        while(True):\n",
    "            if cv2.waitKey(25) & 0xFF == ord('e'):\n",
    "                break\n",
    "            \n",
    "\n",
    "# When everything done, release the video capture and video write objects\n",
    "out1.release()\n",
    "\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print('finished prediction video output!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### questions\n",
    "- Do I have that Xi regresses to the next state, now it is kind of a loop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
