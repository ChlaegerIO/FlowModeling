{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from torch.autograd import Variable\n",
    "#from torch.utils.data import DataLoader\n",
    "#from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "# read videos\n",
    "from os import listdir\n",
    "import cv2\n",
    "# others\n",
    "import os\n",
    "import random\n",
    "#import matplotlib.pyplot as plt\n",
    "# SINDy\n",
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "import sindy_utils as sindy\n",
    "import numpy as np\n",
    "\n",
    "#############################################################################################################\n",
    "# helping function implementation\n",
    "#############################################################################################################\n",
    "\n",
    "def printProgress(epoch, batch_id, loss):\n",
    "    \"\"\"\n",
    "    print progress of the training\n",
    "    epoch: number\n",
    "    batch_id: current batch_id\n",
    "    accuracy:\n",
    "    loss:\n",
    "    \n",
    "    \"\"\"\n",
    "    progress = '='* int((10. * (batch_id+1) / len(train_data)))\n",
    "    progress += '>'\n",
    "    if batch_id == 0:\n",
    "        print('Train Epoche {}: {}% [{}]\\t , loss: {:.6f}'.format(\n",
    "            epoch+1, int(100. * (batch_id+1) / len(train_data)),progress, loss.item()), end='')\n",
    "    else:\n",
    "        print('\\rTrain Epoche {}: {}% [{}]\\t , loss: {:.6f}'.format(\n",
    "            epoch+1, int(100. * (batch_id+1) / len(train_data)),progress, loss.item()), end='', flush = True)\n",
    "        \n",
    "\n",
    "def calculateLoss(network, params):\n",
    "    \"\"\"\n",
    "    calculate the loss of autoencoder and SINDy combined. loss function of:\n",
    "    \n",
    "     O \\   _________           ________  /  O\n",
    "     .    |         | \\  O  / |        |    .\n",
    "     . -  | phi'(x) | -  O  - | phi(z) | -  .\n",
    "     .    |_________| /  O  \\ |________|    .\n",
    "     O /                                 \\  O\n",
    "    x(t)                z(t)               xa(t)\n",
    "    \n",
    "    ||x-phi(z)||_2^2 + lam1 ||dx - (zGrad phi(z)) Theta(z^T) Xi||_2^2 + lam2 ||dz - Theta(z^T) Xi||_2^2 + lam3 ||Xi||_1\n",
    "        decoder      +                   SINDy in dx                  +         SINDy in dz             +   SINDy sparsity\n",
    "     \n",
    "    dz = xGrad phi'(x) dx = (xGrad z) dx\n",
    "    \n",
    "    network: data of the network\n",
    "    params: hyperparameters\n",
    "    \n",
    "    \"\"\"\n",
    "    dx = network['dx']\n",
    "    dx_decode = network['dx_decode']\n",
    "    dz = network['dz']\n",
    "    dz_predict = network['dz_sindy']\n",
    "    Xi_coeff = network['Xi']\n",
    "    rec_loss = network['rec_loss']\n",
    "    sindy_x_loss = torch.mean((dx-dx_decode)**2)\n",
    "    sindy_z_loss = torch.mean((dz-dz_predict)**2)\n",
    "    sparse_loss = torch.mean(torch.abs(Xi_coeff))\n",
    "    \n",
    "    # separate view of each loss\n",
    "    separate_loss = []\n",
    "    separate_loss.append(float(rec_loss))\n",
    "    separate_loss.append(float(sindy_x_loss))\n",
    "    separate_loss.append(float(sindy_z_loss))\n",
    "    separate_loss.append(float(sparse_loss))\n",
    "    \n",
    "    tot_loss = (params['loss_weight_decoder'] * rec_loss\n",
    "                + params['loss_weight_sindy_x'] * sindy_x_loss \n",
    "                + params['loss_weight_sindy_z'] * sindy_z_loss\n",
    "                + params['loss_weight_sindy_regularization'] * sparse_loss)\n",
    "                                                                                        \n",
    "    return tot_loss, separate_loss\n",
    "\n",
    "\n",
    "def calculateSindy(network, params):\n",
    "    '''\n",
    "    Calculate Theta(z), Xi and dz\n",
    "    \n",
    "    '''\n",
    "    z = network['z'].cpu().detach().numpy()\n",
    "    dz = network['dz'].cpu().detach().numpy()\n",
    "    \n",
    "    network['Theta'] = torch.from_numpy(sindy.sindy_library(z, params['poly_order'], include_sine=params['include_sine']))\n",
    "    network['Xi'] = torch.from_numpy(sindy.sindy_fit(network['Theta'], dz, params['sindy_threshold']))\n",
    "    dz_predict = torch.matmul(network['Theta'],network['Xi']).cuda()\n",
    "    \n",
    "    return dz_predict\n",
    "\n",
    "\n",
    "\n",
    "#############################################################################################################\n",
    "# define model parameters\n",
    "#############################################################################################################\n",
    "\n",
    "params = {}\n",
    "\n",
    "# autoencoder settings\n",
    "params['number_epoch'] = 100000                               # number of epochs\n",
    "params['z_dim'] = 5                                     # number of coordinates for SINDy\n",
    "params['batch_size'] = 4                                # batch size\n",
    "params['lr_rate'] = 0.01                                 # learning rate\n",
    "params['weight_decay'] = 1e-8\n",
    "\n",
    "\n",
    "# loss function weighting\n",
    "params['loss_weight_decoder'] = 1.0\n",
    "params['loss_weight_sindy_x'] = 1e-4\n",
    "params['loss_weight_sindy_z'] = 1e-10\n",
    "params['loss_weight_sindy_regularization'] = 1e-4\n",
    "\n",
    "# SINDy parameters\n",
    "params['sindy_threshold'] = 0.5 \n",
    "params['poly_order'] = 4\n",
    "params['include_sine'] = False\n",
    "\n",
    "# video processing\n",
    "path_train = 'Videos/train/'\n",
    "path_test = 'Videos/test/'\n",
    "path_autoencoder = 'results/Autoencoder_#epoch_v1.pt'\n",
    "\n",
    "\n",
    "#############################################################################################################\n",
    "# data preprocessing\n",
    "#############################################################################################################\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('cuda available: ', torch.cuda.is_available())\n",
    "#print('cuda memory', torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "# read the train videos in random order\n",
    "file_names = []\n",
    "for f in listdir(path_train):\n",
    "    if f != 'high_res':\n",
    "        file_names.append(f)\n",
    "\n",
    "random.shuffle(file_names)\n",
    "\n",
    "# define transform to tensor and resize to 1080x1920\n",
    "normalize = transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])    # normalize around mean with sigma (std)\n",
    "# pictures are 16:9 --> 1080x1920, 900x1600, 720x1280, 576x1024, 540x960: 500k pixel, 360x640, 272x480\n",
    "# transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((1080, 1920))])\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# read data to list and transform to tensor\n",
    "train_data_tmp = []\n",
    "train_data = []\n",
    "train_idxOfNewVideo = []\n",
    "for f in file_names:\n",
    "    if len(train_data) > 200:\n",
    "        break\n",
    "    vidcap = cv2.VideoCapture(path_train + f)\n",
    "    success,imgR = vidcap.read()\n",
    "    print('Read training data:',f)\n",
    "    while success:\n",
    "        imgR = cv2.cvtColor(imgR, cv2.COLOR_BGR2RGB)\n",
    "        imgR_tensor = transform(imgR)\n",
    "        train_data_tmp.append(imgR_tensor)\n",
    "        success,imgR = vidcap.read()\n",
    "        if len(train_data_tmp) >= params['batch_size']:\n",
    "            train_data.append(torch.stack(train_data_tmp))\n",
    "            train_data_tmp = []\n",
    "    train_idxOfNewVideo.append(len(train_data))\n",
    "    print('train data: ', len(train_data), len(train_data[0]), len(train_data[0][0]), len(train_data[0][0][0]), len(train_data[0][0][0][0]))\n",
    "\n",
    "print('train data reading done!')\n",
    "\n",
    "\n",
    "# split into validation and training set\n",
    "validation_data = []\n",
    "# take 10% of training set batches to validation set\n",
    "nbr_batch = int(len(train_data)*0.1)\n",
    "for i in range(0,nbr_batch):\n",
    "    choose = random.randint(0, len(train_data)-1)\n",
    "    element = train_data[choose]\n",
    "    validation_data.append(element)\n",
    "    train_data.pop(choose)\n",
    "\n",
    "print('validation data construction done: ', len(validation_data), len(validation_data[0]), len(validation_data[0][0]), len(validation_data[0][0][0]))\n",
    "print('train data: ', len(train_data), len(train_data[0]), len(train_data[0][0]), len(train_data[0][0][0]), len(train_data[0][0][0][0]))\n",
    "\n",
    "\n",
    "# read test videos\n",
    "test_data = []\n",
    "test_idxOfNewVideo = []\n",
    "\n",
    "# read data to list and transform to tensor\n",
    "count = 0\n",
    "# for f in listdir(path_test):\n",
    "#     if f != 'high_res':\n",
    "#         # just for testing (save time)\n",
    "#         # if count == 1:\n",
    "#         #     break\n",
    "#         count += 1\n",
    "#         vidcap = cv2.VideoCapture('Videos/test/' + f)\n",
    "#         success,imgR = vidcap.read()\n",
    "#         print('Read:',f)\n",
    "#         while success:\n",
    "#             imgR = cv2.cvtColor(imgR, cv2.COLOR_BGR2RGB)\n",
    "#             imgR_tensor = transform(imgR)\n",
    "#             test_data.append(imgR_tensor)\n",
    "#             success,imgR = vidcap.read()\n",
    "#         test_idxOfNewVideo.append(len(test_data))\n",
    "    \n",
    "# print('test data reading done: ', len(test_data), len(test_data[0]), len(test_data[0][0]), len(test_data[0][0][0]))\n",
    "\n",
    "\n",
    "#############################################################################################################\n",
    "# autoencoder architecture\n",
    "#############################################################################################################\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__() \n",
    "        self.encode = nn.Sequential(\n",
    "            # encoder: N, 3, 404, 720\n",
    "            nn.Conv2d(3, 16, 2), # N, 16, 403, 719\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 2), # N, 32, 402, 718\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,3), stride=(2,3)), # N, 32, 201, 239              -- pool --\n",
    "            nn.Conv2d(32, 64, 4), # N, 64, 198, 236\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 96, 4), # N, 96, 195, 233\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2), # N, 96, 97, 116                       -- pool --\n",
    "            nn.Conv2d(96, 128, 5), # N, 128, 93, 112\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 150, 5, stride=2, padding=1), # N, 150, 46, 55\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,stride=2), # N, 150, 23, 27                        -- pool --\n",
    "            nn.Conv2d(150, 200, 9, stride=2), # N, 200, 8, 10\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(200*8*10,params['z_dim'])\n",
    "        # Note: nn.MaxPool2d -> use nn.MaxUnpool2d, or use different kernelsize, stride etc to compensate...\n",
    "        # Input [-1, +1] -> use nn.Tanh    \n",
    "        \n",
    "        # note: encoder and decoder are not symmetric\n",
    "        self.decode = nn.Sequential(\n",
    "            nn.ConvTranspose2d(200, 150, 4), # N, 150, 11, 13\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(150, 128, 5, stride=(2,3), padding=(2,2), output_padding=(0,2)), # N, 128, 21, 39\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 96, 4, stride=2, padding=(1,0)), # N, 96, 42, 80\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(96, 64, 8), # N, 64, 49, 87\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 8, stride=2, padding=(2,1), output_padding=(0,1)), # N, 32, 100, 179\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 5, stride=2, padding=1), # N, 16, 201, 359\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 3, 5, stride=2, padding=1, output_padding=(1,1)), # N, 3, 404, 720\n",
    "            nn.ReLU()\n",
    "        )   \n",
    "        \n",
    "        self.fc2 = nn.Linear(params['z_dim'], 200*8*10)\n",
    "\n",
    "    def forward(self, x, z, mode):\n",
    "        '''\n",
    "        x: input for encoder\n",
    "        z: input for decoder\n",
    "        mode: \n",
    "            'train' -> use encoded for decoder\n",
    "            'test'  -> feed z in an get decoded\n",
    "        \n",
    "        '''\n",
    "        if mode == 'train':\n",
    "            #print('train mode')\n",
    "            encoded = self.encode(x)\n",
    "            encoded = encoded.view(-1,200*8*10)\n",
    "            encoded = self.fc1(encoded)\n",
    "\n",
    "            decoded = self.fc2(encoded)\n",
    "            decoded = decoded.view(-1,200,8,10)\n",
    "            decoded = self.decode(decoded)\n",
    "        else:\n",
    "            #print('test mode')\n",
    "            encoded = torch.zeros(1)\n",
    "\n",
    "            decoded = self.fc2(z)\n",
    "            decoded = decoded.view(-1,200,8,10)\n",
    "            decoded = self.decode(decoded)\n",
    "        \n",
    "        return encoded, decoded\n",
    "\n",
    "#############################################################################################################\n",
    "# training loop\n",
    "#############################################################################################################\n",
    "\n",
    "# load model\n",
    "if os.path.isfile(path_autoencoder):\n",
    "    autoencoder = torch.load(path_autoencoder)\n",
    "    print('loaded autoencoder', path_autoencoder)\n",
    "else:\n",
    "    autoencoder = Autoencoder()\n",
    "    print('loaded new autoencoder')\n",
    "\n",
    "autoencoder = autoencoder.cuda()\n",
    "\n",
    "# optimization technique\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=params['lr_rate'], weight_decay=params['weight_decay'])\n",
    "\n",
    "# to save network data\n",
    "network = {}\n",
    "\n",
    "# training function\n",
    "outputs = []\n",
    "def train(epoch):\n",
    "    '''\n",
    "    training function for the autoencoder\n",
    "\n",
    "    '''\n",
    "    for batch_id,img in enumerate(train_data):\n",
    "        img = img.cuda()  \n",
    "        encode_tensor, recon_tensor = autoencoder(img, 0, mode='train')\n",
    "        network['rec_loss'] = criterion(recon_tensor, img)\n",
    "    \n",
    "        # x, z is current batch_id, dx, dz is next one (in else we take dz as current and compare with x from before)\n",
    "        if batch_id == 0:\n",
    "            combined_loss = network['rec_loss']       \n",
    "            network['z'] = encode_tensor#.float()\n",
    "        else:\n",
    "            network['dx'] = img#.float()\n",
    "            network['dz'] = encode_tensor#.float()\n",
    "            network['dz_sindy'] = calculateSindy(network, params).float()\n",
    "            _, network['dx_decode'] = autoencoder(0, network['dz_sindy'], mode='test')\n",
    "            combined_loss, loss_category = calculateLoss(network, params)            # total loss with SINDy\n",
    "            # now advance one step\n",
    "            network['z'] = network['dz']\n",
    "                \n",
    "        # optimization and backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        combined_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print progress\n",
    "        # printProgress(epoch, batch_id, combined_loss)\n",
    "        img = img.detach()\n",
    "    print('\\n')\n",
    "    outputs.append((epoch, float(combined_loss), loss_category))\n",
    "    # delete from cuda\n",
    "    # del encode_tensor\n",
    "    # del recon_tensor\n",
    "\n",
    "    \n",
    "# evaluation function\n",
    "evaluated_dict = {}\n",
    "ae_loss = []\n",
    "sindy_loss = []\n",
    "def evaluate():\n",
    "    '''\n",
    "    evaluation of the training by it's loss\n",
    "\n",
    "    '''\n",
    "    autoencoder.eval()\n",
    "    ae_lossE = 0\n",
    "    sindy_lossE = 0\n",
    "    for i, img in enumerate(validation_data):\n",
    "        img = img.cuda()\n",
    "\n",
    "        # an other video sequence\n",
    "        if i % params['batch_size'] == 0:\n",
    "            # x, z are at the current time\n",
    "            encode_eval_tensor, recon_eval_tensor = autoencoder(img, 0, mode='train')\n",
    "            evaluated_dict['x'] = recon_eval_tensor#.float()\n",
    "            evaluated_dict['z'] = encode_eval_tensor#.float()\n",
    "            eval_theta = torch.from_numpy(sindy.sindy_library(evaluated_dict['z'].cpu().detach().numpy(), params['poly_order'], include_sine=params['include_sine']))\n",
    "            evaluated_dict['dz_sindy'] = torch.matmul(eval_theta,network['Xi']).float().cuda()\n",
    "            _, recon_sindy_eval_tensor = autoencoder(0, evaluated_dict['dz_sindy'], mode='test')\n",
    "            evaluated_dict['dx_sindy'] = recon_sindy_eval_tensor#.float()\n",
    "            # autoencoder loss\n",
    "            ae_lossE += float(F.mse_loss(evaluated_dict['x'], img))\n",
    "        else:\n",
    "            # sindy loss\n",
    "            sindy_lossE += float(F.mse_loss(evaluated_dict['dx_sindy'], img))\n",
    "            evaluated_dict['z'], evaluated_dict['x'] = autoencoder(img, 0, mode='train')            \n",
    "            eval_theta = torch.from_numpy(sindy.sindy_library(evaluated_dict['z'].cpu().detach().numpy(), params['poly_order'], include_sine=params['include_sine']))\n",
    "            evaluated_dict['dz_sindy'] = torch.matmul(eval_theta,network['Xi']).float().cuda()\n",
    "            _, recon_sindy_eval_tensor = autoencoder(0, evaluated_dict['dz_sindy'], mode='test')\n",
    "            evaluated_dict['dx_sindy'] = recon_sindy_eval_tensor#.float()\n",
    "            ae_lossE += float(F.mse_loss(evaluated_dict['x'], img))\n",
    "    \n",
    "    # append average loss of this epoch\n",
    "    ae_loss.append(ae_lossE/len(validation_data))\n",
    "    sindy_loss.append(sindy_lossE/len(validation_data))\n",
    "    # del encode_eval_tensor\n",
    "    # del recon_eval_tensor\n",
    "    # del recon_sindy_eval_tensor\n",
    "\n",
    "# epoch loop\n",
    "for epoch in range(params['number_epoch']):\n",
    "    train(epoch)\n",
    "    print('train epoch', epoch, 'done')\n",
    "    evaluate()\n",
    "    print('evaluate epoch', epoch, 'done')\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        # save model every 100 epoch\n",
    "        name_Ae = 'results/Ae_' + str(epoch) + 'epoch_bs8_lr0-1_z5_sindth0-5_poly5.pt'\n",
    "        name_Xi = 'results/Xi_' + str(epoch) + 'epoch_bs8_lr0-1_z5_sindth0-5_poly5.pt'\n",
    "        name_aeLoss = 'results/AeLoss_' + str(epoch) + 'epoch_bs8_lr0-1_z5_sindth0-5_poly5.pt'\n",
    "        name_sindyLoss = 'results/sindyLoss' + str(epoch) + 'epoch_bs8_lr0-1_z5_sindth0-5_poly5.pt'\n",
    "        name_outputs = 'results/trainOutput' + str(epoch) + 'epoch_bs8_lr0-1_z5_sindth0-5_poly5.pt'\n",
    "        torch.save(autoencoder, name_Ae)\n",
    "        torch.save(network['Xi'], name_Xi)\n",
    "        torch.save(ae_loss, name_aeLoss)\n",
    "        torch.save(sindy_loss, name_sindyLoss)\n",
    "        torch.save(outputs, name_outputs)\n",
    "        print('saved model in epoch', epoch)\n",
    "\n",
    "    torch.cuda.empty_cache()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
