{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "import cv2\n",
    "import random\n",
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "import sindy_utils as sindy\n",
    "\n",
    "# autoencoder architecture\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__() \n",
    "        self.encode = nn.Sequential(\n",
    "            # encoder: N, 3, 404, 720\n",
    "            nn.Conv2d(3, 16, 2), # N, 16, 403, 719\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 2), # N, 32, 402, 718\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,3), stride=(2,3)), # N, 32, 201, 239              -- pool --\n",
    "            nn.Conv2d(32, 64, 4), # N, 64, 198, 236\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 96, 4), # N, 96, 195, 233\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2), # N, 96, 97, 116                       -- pool --\n",
    "            nn.Conv2d(96, 128, 5), # N, 128, 93, 112\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 150, 5, stride=2, padding=1), # N, 150, 46, 55\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,stride=2), # N, 150, 23, 27                        -- pool --\n",
    "            nn.Conv2d(150, 200, 9, stride=2), # N, 200, 8, 10\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(200*8*10,params['z_dim'])\n",
    "        # Note: nn.MaxPool2d -> use nn.MaxUnpool2d, or use different kernelsize, stride etc to compensate...\n",
    "        # Input [-1, +1] -> use nn.Tanh    \n",
    "        \n",
    "        # note: encoder and decoder are not symmetric\n",
    "        self.decode = nn.Sequential(\n",
    "            nn.ConvTranspose2d(200, 150, 4), # N, 150, 11, 13\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(150, 128, 5, stride=(2,3), padding=(2,2), output_padding=(0,2)), # N, 128, 21, 39\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 96, 4, stride=2, padding=(1,0)), # N, 96, 42, 80\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(96, 64, 8), # N, 64, 49, 87\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 8, stride=2, padding=(2,1), output_padding=(0,1)), # N, 32, 100, 179\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 5, stride=2, padding=1), # N, 16, 201, 359\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 3, 5, stride=2, padding=1, output_padding=(1,1)), # N, 3, 404, 720\n",
    "            nn.ReLU()\n",
    "        )   \n",
    "        \n",
    "        self.fc2 = nn.Linear(params['z_dim'], 200*8*10)\n",
    "\n",
    "    def forward(self, x, z, mode):\n",
    "        '''\n",
    "        x: input for encoder\n",
    "        z: input for decoder\n",
    "        mode: \n",
    "            'train' -> use encoded for decoder\n",
    "            'test'  -> feed z in an get decoded\n",
    "        \n",
    "        '''\n",
    "        if mode == 'train':\n",
    "            encoded = self.encode(x)\n",
    "            encoded = encoded.view(-1,200*8*10)\n",
    "            encoded = self.fc1(encoded)\n",
    "\n",
    "            decoded = self.fc2(encoded)\n",
    "            decoded = decoded.view(-1,200,8,10)\n",
    "            decoded = self.decode(decoded)\n",
    "        else:\n",
    "            encoded = torch.zeros(1)\n",
    "\n",
    "            decoded = self.fc2(z)\n",
    "            decoded = decoded.view(-1,200,8,10)\n",
    "            decoded = self.decode(decoded)\n",
    "        \n",
    "        return encoded, decoded\n",
    "\n",
    "    \n",
    "def calculateSindy(z, Xi, poly_order, include_sine_param):\n",
    "    z_new = z.detach().numpy()\n",
    "    \n",
    "    theta = torch.from_numpy(sindy.sindy_library(z_new, poly_order, include_sine=include_sine_param))\n",
    "    \n",
    "    dz_prediction = torch.matmul(theta, Xi).float()\n",
    "    \n",
    "    return dz_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:  30 16 3 404 720\n",
      "train data reading done!\n"
     ]
    }
   ],
   "source": [
    "# loading model\n",
    "path_folder = 'results/v5/'\n",
    "\n",
    "to_load = path_folder+'Ae_4000epoch_bs16_lr1e-5_z2_sindt05_poly5.pt'\n",
    "autoencoder = torch.load(to_load)\n",
    "autoencoder = autoencoder.cpu()\n",
    "\n",
    "# load a train data\n",
    "path_folder_data = 'results/v5/data/'\n",
    "train_data = torch.load(path_folder_data + 'train_data.pt')\n",
    "print('train data: ', len(train_data), len(train_data[0]), len(train_data[0][0]), len(train_data[0][0][0]), len(train_data[0][0][0][0]))\n",
    "print('train data reading done!')\n",
    "\n",
    "## load a validation data\n",
    "#validation_data = torch.load(path_folder_data + 'validation_data.pt')\n",
    "#print('validation data: ', len(validation_data), len(validation_data[0]), len(validation_data[0][0]), len(validation_data[0][0][0]), len(validation_data[0][0][0][0]))\n",
    "#print('validation data reading done!')\n",
    "#\n",
    "## loading test data\n",
    "#test_data = torch.load(path_folder_data + 'test_data.pt')\n",
    "#print('test data: ', len(test_data), len(test_data[0]), len(test_data[0][0]), len(test_data[0][0][0]), len(test_data[0][0][0][0]))\n",
    "#print('test data reading done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def matrixToNorm(x, offset=0, factor=0.95):\n",
    "    x = (x - x.min() + offset) / x.max() * factor\n",
    "    return x\n",
    "\n",
    "poly_order = 4\n",
    "include_sine_param = False\n",
    "threshold_sindy = 1000\n",
    "until = 5                      # choose the number of prediction stepts, 1 step are number of batch_size frames\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use more than 16 frames to get Xi\n",
    "def constructXi(data, zDim):\n",
    "    '''\n",
    "    input: data as a list with shape [len batch_size RGB hight width]\n",
    "    return: Xi\n",
    "    \n",
    "    '''\n",
    "    # processs the data\n",
    "    z_tensor = torch.empty((0, zDim))\n",
    "    data_len = len(data)\n",
    "    for i in range(data_len):\n",
    "        z_tensor_tmp, _ = autoencoder(train_data[i], 0, mode='train')\n",
    "        z_tensor = torch.cat((z_tensor, z_tensor_tmp), 0)\n",
    "        if i % 5 == 0:\n",
    "            print(i, z_tensor.shape)\n",
    "        del z_tensor_tmp\n",
    "\n",
    "    print(z_tensor.shape)\n",
    "    \n",
    "    dz_tensor = z_tensor[2:data_len]\n",
    "    z_tensor = z_tensor[1:data_len-1]\n",
    "    \n",
    "    # calculate sindy and Xi for the data\n",
    "    z = z_tensor.cpu().detach().numpy()\n",
    "    dz = dz_tensor.cpu().detach().numpy()\n",
    "\n",
    "    Theta = torch.from_numpy(sindy.sindy_library(z, poly_order, include_sine=include_sine_param))\n",
    "    Xi = torch.from_numpy(sindy.sindy_fit(Theta, dz, threshold_sindy))\n",
    "    \n",
    "    return Xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([16, 2])\n",
      "5 torch.Size([96, 2])\n",
      "10 torch.Size([176, 2])\n",
      "15 torch.Size([256, 2])\n",
      "20 torch.Size([336, 2])\n",
      "25 torch.Size([416, 2])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:76] data. DefaultCPUAllocator: not enough memory: you tried to allocate 591126528 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15596/2561670110.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mXi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstructXi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzDim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15596/3987220893.py\u001b[0m in \u001b[0;36mconstructXi\u001b[1;34m(data, zDim)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mdata_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mz_tensor_tmp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mz_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_tensor_tmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m5\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\timok\\documents\\git_bachelor\\flowmodeling\\my_models\\neuralnetwork\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15596/2423508195.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, z, mode)\u001b[0m\n\u001b[0;32m     70\u001b[0m         '''\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m             \u001b[0mencoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m             \u001b[0mencoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoded\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[0mencoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\timok\\documents\\git_bachelor\\flowmodeling\\my_models\\neuralnetwork\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\timok\\documents\\git_bachelor\\flowmodeling\\my_models\\neuralnetwork\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\timok\\documents\\git_bachelor\\flowmodeling\\my_models\\neuralnetwork\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\timok\\documents\\git_bachelor\\flowmodeling\\my_models\\neuralnetwork\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\timok\\documents\\git_bachelor\\flowmodeling\\my_models\\neuralnetwork\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    440\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 442\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    443\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:76] data. DefaultCPUAllocator: not enough memory: you tried to allocate 591126528 bytes."
     ]
    }
   ],
   "source": [
    "Xi = constructXi(train_data, zDim=2)\n",
    "\n",
    "print(Xi)\n",
    "\n",
    "print(z)\n",
    "print(dz)\n",
    "print(dz_predict)\n",
    "print(dz_predict2)\n",
    "\n",
    "print(recon2_pred_tensor[1].shape, len(recon2_pred_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a Xi for only one picture, idea: mean of all Xi's with threshold\n",
    "z_tensor, recon_tensor = autoencoder(train_data[0], 0, mode='train')\n",
    "dz_tensor, recon1_tensor = autoencoder(train_data[1], 0, mode='train')\n",
    "\n",
    "recon_tensor = matrixToNorm(recon_tensor)\n",
    "print('max recon_data', recon_tensor.cpu().detach().numpy().max())\n",
    "\n",
    "\n",
    "z = z_tensor.cpu().detach().numpy()\n",
    "dz = dz_tensor.cpu().detach().numpy()\n",
    "\n",
    "Theta = torch.from_numpy(sindy.sindy_library(z, poly_order, include_sine=include_sine_param))\n",
    "Xi = torch.from_numpy(sindy.sindy_fit(Theta, dz, threshold_sindy))\n",
    "dz_predict = torch.matmul(Theta, Xi).float()\n",
    "_, recon1_pred_tensor = autoencoder(0, dz_predict, mode='test')\n",
    "print('max of z_tensor', z_tensor.cpu().detach().numpy().max())\n",
    "print('max of dz_tensor', dz_tensor.cpu().detach().numpy().max())\n",
    "print('max of dz_predict', dz_predict.cpu().detach().numpy().max())\n",
    "\n",
    "# plot autoencoder result\n",
    "\n",
    "for nbImag in range(len(train_data[0])):\n",
    "    plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(train_data[0][nbImag].permute(1,2,0).detach().numpy())\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(recon_tensor[nbImag].permute(1,2,0).detach().numpy())\n",
    "\n",
    "print('One step')\n",
    "recon1_tensor = matrixToNorm(recon1_tensor)\n",
    "recon1_pred_tensor = matrixToNorm(recon1_pred_tensor)\n",
    "# plot sindy result\n",
    "for nbImag in range(len(drecon_tensor)):\n",
    "    plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(recon1_tensor[nbImag].permute(1,2,0).detach().numpy())\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(recon1_pred_tensor[nbImag].permute(1,2,0).detach().numpy())\n",
    "\n",
    "# new calculations\n",
    "dz_tensor, recon2_tensor = autoencoder(train_data[2], 0, mode='train')\n",
    "\n",
    "Theta2 = torch.from_numpy(sindy.sindy_library(dz_predict, poly_order, include_sine=include_sine_param))\n",
    "dz_predict2 = torch.matmul(Theta2, Xi).float()\n",
    "_, recon2_pred_tensor = autoencoder(0, dz_predict2, mode='test')\n",
    "\n",
    "print('Two steps with the same Xi')\n",
    "recon2_tensor = matrixToNorm(recon2_tensor)\n",
    "for i in range(len(recon2_pred_tensor)):\n",
    "    recon2_pred_tensor[i] = matrixToNorm(recon2_pred_tensor[i])\n",
    "for nbImag in range(len(drecon_tensor)):\n",
    "    plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(recon2_tensor[nbImag].permute(1,2,0).detach().numpy())\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(recon2_pred_tensor[nbImag].permute(1,2,0).detach().numpy())\n",
    "\n",
    "## test model\n",
    "#def test(data):\n",
    "#    video_reconstruction = []\n",
    "#    # predict videos\n",
    "#    for vid_nbr in range(0, len(test_idxOfNewVideo)):\n",
    "#        print('video number', vid_nbr)\n",
    "#        # first step encode first batch\n",
    "#        img = data[test_idxOfNewVideo[vid_nbr]]\n",
    "#        encode_tensor, recon_tensor = autoencoder(img, 0, mode='train')\n",
    "#        # too big\n",
    "#        if vid_nbr == 2:\n",
    "#            break\n",
    "#        \n",
    "#        # predict the future using only sindy model, new video starts always at position vid_nbr * until\n",
    "#        for i in range(0, until):\n",
    "#            #print('pred', i)\n",
    "#            video_reconstruction.append(recon_tensor)\n",
    "#            dz_tensor = calculateSindy(encode_tensor, Xi, poly_order, include_sine_param)\n",
    "#            encode_tensor = dz_tensor\n",
    "#            _, recon_tensor = autoencoder(0, dz_tensor, mode='test')\n",
    "#            \n",
    "#    return video_reconstruction\n",
    "#\n",
    "#\n",
    "## test for different models or epoch number, TODO\n",
    "#video_output = test(train_debug)\n",
    "#print('prediction done!')\n",
    "#\n",
    "##del test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first picture comparision\n",
    "print(len(video_output))\n",
    "#for i in range(0, len(video_output)):\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(train_debug[0][0].permute(1,2,0).detach().numpy())\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(video_output[0][0].permute(1,2,0).detach().numpy())\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(train_debug[1][0].permute(1,2,0).detach().numpy())\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(video_output[1][0].permute(1,2,0).detach().numpy())\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(train_debug[2][0].permute(1,2,0).detach().numpy())\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(video_output[2][0].permute(1,2,0).detach().numpy())\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(train_debug[3][0].permute(1,2,0).detach().numpy())\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(video_output[3][0].permute(1,2,0).detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make videos\n",
    "frame_width = len(video_output[0][0][0][0])\n",
    "frame_height = len(video_output[0][0][0])\n",
    "fps = 25.0\n",
    "\n",
    "# write different videos\n",
    "#forcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "forcc = cv2.VideoWriter_fourcc('D','I','V','3')\n",
    "#forcc = cv2.VideoWriter_fourcc('F','M','P','4')\n",
    "out1 = cv2.VideoWriter('figures/run1_lre-5_z5_poly4/videoTest.avi', forcc, 1, (frame_width,frame_height))\n",
    "#out2 = cv2.VideoWriter('video2.mov',cv2.VideoWriter_fourcc('M','J','P','G'), fps, (frame_width,frame_height))\n",
    "#out3 = cv2.VideoWriter('video3.mov',cv2.VideoWriter_fourcc('M','J','P','G'), fps, (frame_width,frame_height))\n",
    "    \n",
    "print('output video', len(video_output), len(video_output[0]), len(video_output[0][0]), len(video_output[0][0][0]), len(video_output[0][0][0][0]))\n",
    "\n",
    "for vid_nbr in range(0, len(test_idxOfNewVideo)):\n",
    "    if vid_nbr == 1:\n",
    "        break\n",
    "    # undo batch structure\n",
    "    videoProcessing = []\n",
    "    count = -1\n",
    "    for img in range(0, len(video_output)*len(video_output[0])):\n",
    "        imgIn_batch = img % batch_size\n",
    "        # new batch\n",
    "        if imgIn_batch == 0:\n",
    "            count += 1\n",
    "        img_toAppend = video_output[count][imgIn_batch]\n",
    "        videoProcessing.append(img_toAppend)\n",
    "        \n",
    "    #del video_output\n",
    "    print('video currently procession', len(videoProcessing), len(videoProcessing[0]), len(videoProcessing[0][0]), len(videoProcessing[0][0][0]))\n",
    "    \n",
    "    for img in range(0,len(videoProcessing)):\n",
    "        frame_local = np.transpose(videoProcessing[img].detach().numpy(), [1,2,0])\n",
    "        frame_local = cv2.cvtColor(frame_local, cv2.COLOR_RGB2BGR)\n",
    "        # print(frame_local) --> seems unstable, not a number and doesn't save it as a video\n",
    "        out1.write(frame_local.shape)\n",
    "        # show video\n",
    "        cv2.imshow('Frame',frame_local)\n",
    "\n",
    "        # Press Q on keyboard to  exit\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q') and img >= 10:\n",
    "            break\n",
    "\n",
    "    # When everything done, release the video capture and video write objects\n",
    "    out1.release()\n",
    "\n",
    "    # Closes all the frames\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "print('finished prediction video output!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
