{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-04 11:11:38\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "import cv2\n",
    "import random\n",
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "import sindy_utils as sindy\n",
    "from datetime import datetime\n",
    "print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "# autoencoder architecture\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__() \n",
    "        self.encode = nn.Sequential(\n",
    "            # encoder: N, 3, 404, 720\n",
    "            nn.Conv2d(3, 16, 2), # N, 16, 403, 719\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 2), # N, 32, 402, 718\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,3), stride=(2,3)), # N, 32, 201, 239              -- pool --\n",
    "            nn.Conv2d(32, 64, 4), # N, 64, 198, 236\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 96, 4), # N, 96, 195, 233\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2), # N, 96, 97, 116                       -- pool --\n",
    "            nn.Conv2d(96, 128, 5), # N, 128, 93, 112\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 150, 5, stride=2, padding=1), # N, 150, 46, 55\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,stride=2), # N, 150, 23, 27                        -- pool --\n",
    "            nn.Conv2d(150, 200, 9, stride=2), # N, 200, 8, 10\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(200*8*10,params['z_dim'])\n",
    "        # Note: nn.MaxPool2d -> use nn.MaxUnpool2d, or use different kernelsize, stride etc to compensate...\n",
    "        # Input [-1, +1] -> use nn.Tanh    \n",
    "        \n",
    "        # note: encoder and decoder are not symmetric\n",
    "        self.decode = nn.Sequential(\n",
    "            nn.ConvTranspose2d(200, 150, 4), # N, 150, 11, 13\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(150, 128, 5, stride=(2,3), padding=(2,2), output_padding=(0,2)), # N, 128, 21, 39\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 96, 4, stride=2, padding=(1,0)), # N, 96, 42, 80\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(96, 64, 8), # N, 64, 49, 87\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 8, stride=2, padding=(2,1), output_padding=(0,1)), # N, 32, 100, 179\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 5, stride=2, padding=1), # N, 16, 201, 359\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 3, 5, stride=2, padding=1, output_padding=(1,1)), # N, 3, 404, 720\n",
    "            nn.ReLU()\n",
    "        )   \n",
    "        \n",
    "        self.fc2 = nn.Linear(params['z_dim'], 200*8*10)\n",
    "\n",
    "    def forward(self, x, z, mode):\n",
    "        '''\n",
    "        x: input for encoder\n",
    "        z: input for decoder\n",
    "        mode: \n",
    "            'train' -> use encoded for decoder\n",
    "            'test'  -> feed z in an get decoded\n",
    "        \n",
    "        '''\n",
    "        if mode == 'train':\n",
    "            encoded = self.encode(x)\n",
    "            encoded = encoded.view(-1,200*8*10)\n",
    "            encoded = self.fc1(encoded)\n",
    "\n",
    "            decoded = self.fc2(encoded)\n",
    "            decoded = decoded.view(-1,200,8,10)\n",
    "            decoded = self.decode(decoded)\n",
    "        else:\n",
    "            encoded = torch.zeros(1)\n",
    "\n",
    "            decoded = self.fc2(z)\n",
    "            decoded = decoded.view(-1,200,8,10)\n",
    "            decoded = self.decode(decoded)\n",
    "        \n",
    "        return encoded, decoded\n",
    "\n",
    "    \n",
    "def calculateSindy(z, Xi, poly_order, include_sine_param):\n",
    "    z_new = z.detach().numpy()\n",
    "    \n",
    "    theta = torch.from_numpy(sindy.sindy_library(z_new, poly_order, include_sine=include_sine_param))\n",
    "    \n",
    "    dz_prediction = torch.matmul(theta, Xi).float()\n",
    "    \n",
    "    return dz_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:  30 16 3 404 720\n",
      "train data reading done!\n",
      "validation data:  4 16 3 404 720\n",
      "validation data reading done!\n",
      "test data:  4 16 3 404 720\n",
      "test data reading done!\n",
      "Xi loaded succesfully!\n",
      "tensor([[ 0.9273,  0.0000, -2.8082,  0.2431],\n",
      "        [ 0.6693,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.1200,  1.0689, -0.2860, -0.3664],\n",
      "        [ 0.0000,  0.0000,  0.2880,  0.0000],\n",
      "        [ 0.0000,  0.1291,  0.5453,  0.7441],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.2862,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.1459,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# loading model\n",
    "path_folder = 'results/v5_3_z4_newSindy/'\n",
    "\n",
    "to_load = path_folder+'Ae_5000epoch_bs16_lr1e-05_z4_sindt01_poly5.pt'\n",
    "autoencoder = torch.load(to_load)\n",
    "autoencoder = autoencoder.cpu()\n",
    "\n",
    "# load a train data\n",
    "path_folder_data = path_folder+'data/'\n",
    "train_data = torch.load(path_folder_data + 'train_data.pt')\n",
    "print('train data: ', len(train_data), len(train_data[0]), len(train_data[0][0]), len(train_data[0][0][0]), len(train_data[0][0][0][0]))\n",
    "print('train data reading done!')\n",
    "\n",
    "# load a validation data\n",
    "validation_data = torch.load(path_folder_data + 'validation_data.pt')\n",
    "print('validation data: ', len(validation_data), len(validation_data[0]), len(validation_data[0][0]), len(validation_data[0][0][0]), len(validation_data[0][0][0][0]))\n",
    "print('validation data reading done!')\n",
    "\n",
    "# loading test data\n",
    "test_data = torch.load(path_folder_data + 'test_data.pt')\n",
    "print('test data: ', len(test_data), len(test_data[0]), len(test_data[0][0]), len(test_data[0][0][0]), len(test_data[0][0][0][0]))\n",
    "print('test data reading done!')\n",
    "\n",
    "\n",
    "# load Xi\n",
    "Xi = torch.load(path_folder + 'Xi_5000epoch_bs16_lr1e-05_z4_sindt01_poly5.pt')\n",
    "print('Xi loaded succesfully!')\n",
    "print(Xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def matrixToNorm(x, offset=0, factor=0.95):\n",
    "    x = (x - x.min() + offset) / x.max() * factor\n",
    "    return x\n",
    "\n",
    "############################## configurations #####################################\n",
    "poly_order = 5\n",
    "include_sine_param = False\n",
    "threshold_sindy = 0.1\n",
    "until = 5                      # choose the number of prediction stepts, 1 step are number of batch_size frames\n",
    "params = {}\n",
    "params['z_dim'] = 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting images of autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "whichData = 1      # 1: train_data, 2: validation_data, 3: test_data\n",
    "if whichData == 1:\n",
    "    data = train_data\n",
    "elif whichData:\n",
    "    data = validation_data\n",
    "else:\n",
    "    data = test_data\n",
    "\n",
    "# plot autoencoder result\n",
    "z_tensor, recon_tensor = autoencoder(data[0], 0, mode='train')\n",
    "for nbImag in range(len(recon_tensor)):\n",
    "    plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(data[0][nbImag].permute(1,2,0).detach().numpy())\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(recon_tensor[nbImag].permute(1,2,0).detach().numpy())\n",
    "    \n",
    "# plot an other example from a random point in data\n",
    "plt.show()\n",
    "print('next random example')\n",
    "randPlace = random.randint(0, len(data)-1)\n",
    "z_tensor, recon_tensor = autoencoder(data[randPlace], 0, mode='train')\n",
    "# plot sindy result\n",
    "for nbImag in range(len(recon_tensor)):\n",
    "    plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(data[randPlace][nbImag].permute(1,2,0).detach().numpy())\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(recon_tensor[nbImag].permute(1,2,0).detach().numpy())\n",
    "plt.savefig('figures/v5_3_z4_newSindy/autoencoderResult.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting images for the first glance of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "whichData = 1      # 1: train_data, 2: validation_data, 3: test_data\n",
    "if whichData == 1:\n",
    "    data = train_data\n",
    "elif whichData:\n",
    "    data = validation_data\n",
    "else:\n",
    "    data = test_data\n",
    "    \n",
    "z_tensor, recon_tensor = autoencoder(data[0], 0, mode='train')\n",
    "\n",
    "# plot zero step\n",
    "print('Zero step')\n",
    "for nbImag in range(len(recon_tensor)):\n",
    "    plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(recon_tensor[nbImag].permute(1,2,0).detach().numpy())\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(recon_tensor[nbImag].permute(1,2,0).detach().numpy())\n",
    "plt.show()    \n",
    "recon_tensor = matrixToNorm(recon_tensor)\n",
    "print('max recon_data', recon_tensor.cpu().detach().numpy().max())\n",
    "\n",
    "\n",
    "print('1. step')\n",
    "dz_tensor, recon1_tensor = autoencoder(data[1], 0, mode='train')\n",
    "z = z_tensor.cpu().detach().numpy()\n",
    "\n",
    "Theta = torch.from_numpy(sindy.sindy_library(z, poly_order, include_sine=include_sine_param))\n",
    "dz_predict = torch.matmul(Theta, Xi).float()\n",
    "_, recon1_pred_tensor = autoencoder(0, dz_predict, mode='test')\n",
    "print('max of z_tensor', z_tensor.cpu().detach().numpy().max())\n",
    "print('max of dz_tensor', dz_tensor.cpu().detach().numpy().max())\n",
    "print('max of dz_predict', dz_predict.cpu().detach().numpy().max())\n",
    "\n",
    "recon1_tensor = matrixToNorm(recon1_tensor)\n",
    "recon1_pred_tensor = matrixToNorm(recon1_pred_tensor)\n",
    "# plot sindy result\n",
    "for nbImag in range(len(recon1_tensor)):\n",
    "    plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(recon1_tensor[nbImag].permute(1,2,0).detach().numpy())\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(recon1_pred_tensor[nbImag].permute(1,2,0).detach().numpy())\n",
    "plt.savefig('figures/v5_3_z4_newSindy/prediction1StepResult.png')\n",
    "plt.show()\n",
    "\n",
    "print('2. Step')\n",
    "# new calculations\n",
    "dz_tensor, recon2_tensor = autoencoder(data[2], 0, mode='train')\n",
    "\n",
    "Theta2 = torch.from_numpy(sindy.sindy_library(dz_predict, poly_order, include_sine=include_sine_param))\n",
    "dz_predict2 = torch.matmul(Theta2, Xi).float()\n",
    "_, recon2_pred_tensor = autoencoder(0, dz_predict2, mode='test')\n",
    "\n",
    "recon2_tensor = matrixToNorm(recon2_tensor)\n",
    "#for i in range(len(recon2_pred_tensor)):\n",
    "#    recon2_pred_tensor[i] = matrixToNorm(recon2_pred_tensor[i])\n",
    "for nbImag in range(len(recon2_tensor)):\n",
    "    plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(recon2_tensor[nbImag].permute(1,2,0).detach().numpy())\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(recon2_pred_tensor[nbImag].permute(1,2,0).detach().numpy())\n",
    "plt.savefig('figures/v5_3_z4_newSindy/prediction2StepResult.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting in z dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "whichData = 1      # 1: train_data, 2: validation_data, 3: test_data\n",
    "if whichData == 1:\n",
    "    data = train_data\n",
    "elif whichData:\n",
    "    data = validation_data\n",
    "else:\n",
    "    data = test_data\n",
    "    \n",
    "ChooseLength = len(data)\n",
    "batch_size = 16\n",
    "\n",
    "# compute true z\n",
    "z_true = np.empty((ChooseLength*batch_size, params['z_dim']))\n",
    "for index in range(0, ChooseLength):\n",
    "    z_tensor, recon_tensor = autoencoder(data[index], 0, mode='train')\n",
    "    z_true[index*batch_size:(index+1)*batch_size][:] = z_tensor.cpu().detach().numpy()\n",
    "    if index % 5 == 0: print(index)\n",
    "\n",
    "print('z_true dimension', z_true.shape)\n",
    "    \n",
    "# print graph(s) for z_true\n",
    "print('graph(s) for z_true')\n",
    "for graph in range(z_true.shape[1]):\n",
    "    plt.figure()\n",
    "    x = np.linspace(0, z_true.shape[0], z_true.shape[0])\n",
    "    y = z_true[:,graph]\n",
    "    plt.plot(x, y)\n",
    "    plt.savefig('figures/v5_3_z4_newSindy/graph_zTrue' +str(graph)+ '.png')\n",
    "plt.show()\n",
    "\n",
    "# compute sindy z predition based on first one\n",
    "z_tensor_first, recon_tensor_first = autoencoder(data[0], 0, mode='train')\n",
    "z = z_tensor_first.cpu().detach().numpy()\n",
    "z_sindy = np.empty((ChooseLength*batch_size, params['z_dim']))\n",
    "z_sindy[0:16] = z\n",
    "for index_s in range(0, ChooseLength-1):\n",
    "    Theta = torch.from_numpy(sindy.sindy_library(z, poly_order, include_sine=include_sine_param))\n",
    "    dz_predict = torch.matmul(Theta, Xi).float()\n",
    "    z_sindy[(index_s+1)*batch_size:(index_s+2)*batch_size] = dz_predict.cpu().detach().numpy()\n",
    "    z = dz_predict\n",
    "    \n",
    "    \n",
    "# print graph(s) for z_sindy\n",
    "print('graph(s) for z_sindy prediction')\n",
    "for graph in range(z_sindy.shape[1]):\n",
    "    plt.figure()\n",
    "    x = np.linspace(0, z_sindy.shape[0], z_sindy.shape[0])\n",
    "    y = z_sindy[:,graph]\n",
    "    plt.plot(x, y)\n",
    "    plt.savefig('figures/v5_3_z4_newSindy/graph_zSindy' +str(graph)+ '.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing a video with sindy steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred 0\n",
      "pred 5\n",
      "prediction done!\n"
     ]
    }
   ],
   "source": [
    "until = 10\n",
    "\n",
    "# test model\n",
    "def test(data):\n",
    "    video_reconstruction = []\n",
    "    # predict videos\n",
    "    # first step encode first batch\n",
    "    img = data[0]\n",
    "    encode_tensor, recon_tensor = autoencoder(img, 0, mode='train')\n",
    "    \n",
    "    # predict the future using only sindy model, new video starts always at position vid_nbr * until\n",
    "    for i in range(0, until):\n",
    "        if i % 5 == 0: print('pred', i)\n",
    "        video_reconstruction.append(recon_tensor)\n",
    "        dz_tensor = calculateSindy(encode_tensor, Xi, poly_order, include_sine_param)\n",
    "        _, recon_tensor = autoencoder(0, dz_tensor, mode='test')\n",
    "        encode_tensor = dz_tensor\n",
    "            \n",
    "    return video_reconstruction\n",
    "\n",
    "\n",
    "video_output = test(test_data)\n",
    "print('prediction done!')\n",
    "\n",
    "#del test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output video 10 16 3 404 720\n",
      "video currently procession 160 3 404 720\n",
      "finished prediction video output!\n"
     ]
    }
   ],
   "source": [
    "# make videos\n",
    "frame_width = len(video_output[0][0][0][0])\n",
    "frame_height = len(video_output[0][0][0])\n",
    "fps = 25.0\n",
    "batch_size = 16\n",
    "video_output = video_output\n",
    "\n",
    "# write different videos\n",
    "#forcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "forcc = cv2.VideoWriter_fourcc('D','I','V','3')\n",
    "#forcc = cv2.VideoWriter_fourcc('F','M','P','4')\n",
    "out1 = cv2.VideoWriter('figures/v5_3_z4_newSindy/videoSindyPrediction.avi', forcc, fps, (frame_width,frame_height))\n",
    "#out2 = cv2.VideoWriter('video2.mov',cv2.VideoWriter_fourcc('M','J','P','G'), fps, (frame_width,frame_height))\n",
    "#out3 = cv2.VideoWriter('video3.mov',cv2.VideoWriter_fourcc('M','J','P','G'), fps, (frame_width,frame_height))\n",
    "\n",
    "\n",
    "print('output video', len(video_output), len(video_output[0]), len(video_output[0][0]), len(video_output[0][0][0]), len(video_output[0][0][0][0]))\n",
    "\n",
    "# undo batch structure\n",
    "videoProcessing = []\n",
    "count = -1\n",
    "for img in range(0, len(video_output)*len(video_output[0])):\n",
    "    imgIn_batch = img % batch_size\n",
    "    # new batch\n",
    "    if imgIn_batch == 0:\n",
    "        count += 1\n",
    "    img_toAppend = video_output[count][imgIn_batch]\n",
    "    videoProcessing.append(img_toAppend)\n",
    "        \n",
    "#del video_output\n",
    "print('video currently procession', len(videoProcessing), len(videoProcessing[0]), len(videoProcessing[0][0]), len(videoProcessing[0][0][0]))\n",
    "    \n",
    "for img in range(0,len(videoProcessing)):\n",
    "    frame_local = np.transpose(videoProcessing[img].detach().numpy(), [1,2,0])\n",
    "    frame_local = cv2.cvtColor(frame_local, cv2.COLOR_RGB2BGR)\n",
    "    # print(frame_local) --> seems unstable, not a number and doesn't save it as a video\n",
    "    out1.write(frame_local.shape)\n",
    "    # show video\n",
    "    cv2.imshow('Frame',frame_local)\n",
    "\n",
    "    # Press Q on keyboard to  exit\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q') and img >= 10:\n",
    "        break\n",
    "    \n",
    "    # Press w on keyboard to wait\n",
    "    if cv2.waitKey(25) & 0xFF == ord('w'):\n",
    "        while(True):\n",
    "            if cv2.waitKey(25) & 0xFF == ord('e'):\n",
    "                break\n",
    "            \n",
    "\n",
    "# When everything done, release the video capture and video write objects\n",
    "out1.release()\n",
    "\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print('finished prediction video output!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### questions\n",
    "- Do I have that Xi regresses to the next state, now it is kind of a loop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use more than 16 frames to get Xi\n",
    "def constructXi(data, zDim):\n",
    "    '''\n",
    "    input: data as a list with shape [len batch_size RGB hight width]\n",
    "    return: Xi\n",
    "    \n",
    "    '''\n",
    "    # processs the data\n",
    "    z_tensor = torch.empty((0, zDim))\n",
    "    data_len = len(data)\n",
    "    for i in range(data_len):\n",
    "        if i == 20:\n",
    "            break\n",
    "        z_tensor_tmp, _ = autoencoder(train_data[i], 0, mode='train')\n",
    "        z_tensor = torch.cat((z_tensor, z_tensor_tmp), 0)\n",
    "        if i % 5 == 0:\n",
    "            print(i, z_tensor.shape)\n",
    "        del z_tensor_tmp\n",
    "\n",
    "    print(z_tensor.shape)\n",
    "    \n",
    "    dz_tensor = z_tensor[2:data_len]\n",
    "    z_tensor = z_tensor[1:data_len-1]\n",
    "    \n",
    "    # calculate sindy and Xi for the data\n",
    "    z = z_tensor.cpu().detach().numpy()\n",
    "    dz = dz_tensor.cpu().detach().numpy()\n",
    "\n",
    "    Theta = torch.from_numpy(sindy.sindy_library(z, poly_order, include_sine=include_sine_param))\n",
    "    Xi = torch.from_numpy(sindy.sindy_fit(Theta, dz, threshold_sindy))\n",
    "    \n",
    "    return Xi\n",
    "\n",
    "Xi = constructXi(train_data, zDim=2)\n",
    "\n",
    "print(Xi)\n",
    "\n",
    "print(z)\n",
    "print(dz)\n",
    "print(dz_predict)\n",
    "print(dz_predict2)\n",
    "\n",
    "print(recon2_pred_tensor[1].shape, len(recon2_pred_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = {}\n",
    "network['Xi'] = Xi\n",
    "params['poly_order'] = 4\n",
    "params['sindy_threshold'] = 0.1\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.0001, weight_decay=0)\n",
    "pos = 0\n",
    "z_tensor_tmp = torch.empty((0, params['z_dim'])).cpu()\n",
    "for batch_id, img_tensor in enumerate(train_data):\n",
    "    img_tensor = img_tensor.cpu()\n",
    "    encode_tensor, recon_tensor = autoencoder(img_tensor, 0, mode='train')\n",
    "    z_tensor_tmp = torch.cat((z_tensor_tmp, encode_tensor), 0)        # save all z-states for Xi calculation\n",
    "    network['ae_loss'] = criterion(recon_tensor, img_tensor)\n",
    "\n",
    "    # spacial case for first sindy epoch, we have no Xi yet\n",
    "    if False:\n",
    "        combined_loss = network['ae_loss']   \n",
    "    # x, z is current batch_id, dx, dz is next one (in else we take dz as current and compare with x from before, the excite to current step)\n",
    "    elif batch_id == 0:\n",
    "        pos += 1\n",
    "        combined_loss = network['ae_loss']       \n",
    "        network['z'] = encode_tensor#.float()  \n",
    "    else:\n",
    "        network['dx'] = img_tensor#.float()\n",
    "        network['dz'] = encode_tensor#.float()\n",
    "        Theta = torch.from_numpy(sindy.sindy_library(network['z'].cpu().detach().numpy(), params['poly_order'], include_sine=False))\n",
    "        network['dz_sindy'] = torch.matmul(Theta, network['Xi']).float().cpu()\n",
    "        _, network['dx_sindy'] = autoencoder(0, network['dz_sindy'], mode='test')\n",
    "        #combined_loss = networkLoss()            # total loss with SINDy\n",
    "        # now advance one step\n",
    "        network['z'] = network['dz']\n",
    "                    \n",
    "    # optimization and backpropagation\n",
    "    #optimizer.zero_grad()\n",
    "    #combined_loss.backward()\n",
    "    #optimizer.step()\n",
    "\n",
    "    # tensorboard\n",
    "    #writer.add_scalar(f'Training loss / batch; ae: {nbrAeEpoch}epochs / sindy: {nbrSindyEpoch}epochs', combined_loss, global_step=steps)\n",
    "    #writer.add_histogram('fc1', autoencoder.fc1.weight, global_step=steps)\n",
    "    #steps += 1\n",
    "\n",
    "    # printProgress(epoch, batch_id, combined_loss)\n",
    "    img_tensor = img_tensor.detach()\n",
    "        \n",
    "# calculate Xi for the hole batch\n",
    "print(z_tensor_tmp.shape)\n",
    "dz_tensor_tmp = z_tensor_tmp[16:len(z_tensor_tmp)].cpu().detach().numpy()\n",
    "z_tensor_tmp = z_tensor_tmp[0:len(z_tensor_tmp)-16].cpu().detach().numpy()\n",
    "\n",
    "print(z_tensor_tmp.shape)\n",
    "print(dz_tensor_tmp.shape)\n",
    "        \n",
    "Theta = torch.from_numpy(sindy.sindy_library(z_tensor_tmp, params['poly_order'], include_sine=False))\n",
    "network['Xi'] = torch.from_numpy(sindy.sindy_fit(Theta, dz_tensor_tmp, params['sindy_threshold']))\n",
    "z_tensor_tmp = torch.empty((0, params['z_dim'])).cpu()\n",
    "dz_tensor_tmp = torch.empty((0, params['z_dim'])).cpu()\n",
    "del z_tensor_tmp\n",
    "del dz_tensor_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(z_tensor_tmp.shape)\n",
    "print(len(z_tensor_tmp), z_tensor_tmp.shape[0])\n",
    "\n",
    "#dz_tensor_tmp = z_tensor_tmp[16:len(z_tensor_tmp)].cpu().detach().numpy()\n",
    "#z_tensor_tmp = z_tensor_tmp[0:len(z_tensor_tmp)-16].cpu().detach().numpy()\n",
    "\n",
    "print(z_tensor_tmp.shape)\n",
    "print(dz_tensor_tmp.shape)\n",
    "\n",
    "# print graph(s) for z_true\n",
    "print('graph(s)')\n",
    "for graph in range(z_tensor_tmp.shape[1]):\n",
    "    plt.figure()\n",
    "    x = np.linspace(0, 160, 160)\n",
    "    y = z_tensor_tmp[0:160,graph]\n",
    "    plt.plot(x, y)\n",
    "plt.show()\n",
    "\n",
    "print('graph(s) dz')\n",
    "for graph in range(dz_tensor_tmp.shape[1]):\n",
    "    plt.figure()\n",
    "    x = np.linspace(0, 160, 160)\n",
    "    y = dz_tensor_tmp[0:160,graph]\n",
    "    plt.plot(x, y)\n",
    "plt.show()\n",
    "\n",
    "ThetaTest = torch.from_numpy(sindy.sindy_library(z_tensor_tmp, params['poly_order'], include_sine=False))\n",
    "XiTest = torch.from_numpy(sindy.sindy_fit(ThetaTest, dz_tensor_tmp, params['sindy_threshold']))\n",
    "z = z_tensor_tmp[0:16]\n",
    "z_sindyTest = np.empty((160,2))\n",
    "for index_s in range(0, 10):\n",
    "    z_sindyTest[(index_s)*batch_size:(index_s+1)*batch_size] = z\n",
    "    ThetaTest = torch.from_numpy(sindy.sindy_library(z, params['poly_order'], include_sine=False))\n",
    "    dz_predictTest = torch.matmul(ThetaTest, XiTest).float()\n",
    "    z = dz_predictTest.cpu().detach().numpy()\n",
    "\n",
    "print('graph(s) dz predication')\n",
    "for graph in range(z_sindyTest.shape[1]):\n",
    "    plt.figure()\n",
    "    x = np.linspace(0, z_sindyTest.shape[0], z_sindyTest.shape[0])\n",
    "    y = z_sindyTest[:,graph]\n",
    "    plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
