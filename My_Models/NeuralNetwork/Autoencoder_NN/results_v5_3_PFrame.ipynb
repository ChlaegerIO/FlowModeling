{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "import cv2\n",
    "import random\n",
    "from scipy.signal import savgol_filter\n",
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "import sindy_utils as sindy\n",
    "from datetime import datetime\n",
    "print(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "# autoencoder architecture\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__() \n",
    "        self.encode = nn.Sequential(\n",
    "            # encoder: N, 3, 404, 720\n",
    "            nn.Conv2d(3, 16, 2), # N, 16, 403, 719\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 2), # N, 32, 402, 718\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,3), stride=(2,3)), # N, 32, 201, 239              -- pool --\n",
    "            nn.Conv2d(32, 64, 4), # N, 64, 198, 236\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 96, 4), # N, 96, 195, 233\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2), # N, 96, 97, 116                       -- pool --\n",
    "            nn.Conv2d(96, 128, 5), # N, 128, 93, 112\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 150, 5, stride=2, padding=1), # N, 150, 46, 55\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,stride=2), # N, 150, 23, 27                        -- pool --\n",
    "            nn.Conv2d(150, 200, 9, stride=2), # N, 200, 8, 10\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(200*8*10,gl_zDim)\n",
    "        # Note: nn.MaxPool2d -> use nn.MaxUnpool2d, or use different kernelsize, stride etc to compensate...\n",
    "        # Input [-1, +1] -> use nn.Tanh    \n",
    "        \n",
    "        # note: encoder and decoder are not symmetric\n",
    "        self.decode = nn.Sequential(\n",
    "            nn.ConvTranspose2d(200, 150, 4), # N, 150, 11, 13\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(150, 128, 5, stride=(2,3), padding=(2,2), output_padding=(0,2)), # N, 128, 21, 39\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 96, 4, stride=2, padding=(1,0)), # N, 96, 42, 80\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(96, 64, 8), # N, 64, 49, 87\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 8, stride=2, padding=(2,1), output_padding=(0,1)), # N, 32, 100, 179\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 5, stride=2, padding=1), # N, 16, 201, 359\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 3, 5, stride=2, padding=1, output_padding=(1,1)), # N, 3, 404, 720\n",
    "            nn.ReLU()\n",
    "        )   \n",
    "        \n",
    "        self.fc2 = nn.Linear(gl_zDim, 200*8*10)\n",
    "\n",
    "    def forward(self, x, z, mode):\n",
    "        '''\n",
    "        x: input for encoder\n",
    "        z: input for decoder\n",
    "        mode: \n",
    "            'train' -> use encoded for decoder\n",
    "            'test'  -> feed z in an get decoded\n",
    "        \n",
    "        '''\n",
    "        if mode == 'train':\n",
    "            encoded = self.encode(x)\n",
    "            encoded = encoded.view(-1,200*8*10)\n",
    "            encoded = self.fc1(encoded)\n",
    "\n",
    "            decoded = self.fc2(encoded)\n",
    "            decoded = decoded.view(-1,200,8,10)\n",
    "            decoded = self.decode(decoded)\n",
    "        else:\n",
    "            encoded = torch.zeros(1)\n",
    "\n",
    "            decoded = self.fc2(z)\n",
    "            decoded = decoded.view(-1,200,8,10)\n",
    "            decoded = self.decode(decoded)\n",
    "        \n",
    "        return encoded, decoded\n",
    "\n",
    "    \n",
    "def calculateSindy(z, Xi, poly_order, include_sine_param):\n",
    "    z_new = z.detach().numpy()\n",
    "    \n",
    "    theta = torch.from_numpy(sindy.sindy_library(z_new, poly_order, include_sine=include_sine_param))\n",
    "    \n",
    "    dz_prediction = torch.matmul(theta, Xi).float()\n",
    "    \n",
    "    return dz_prediction\n",
    "\n",
    "# use more than 16 frames to get Xi\n",
    "def constructXi(data, zDim):\n",
    "    '''\n",
    "    input: data as a list with shape [len batch_size RGB hight width]\n",
    "    return: Xi\n",
    "    \n",
    "    '''\n",
    "    # processs the data\n",
    "    z_tensor = torch.empty((0, zDim))\n",
    "    data_len = len(data)\n",
    "    for i in range(data_len):\n",
    "        if i == 20:\n",
    "            break\n",
    "        z_tensor_tmp, _ = autoencoder(train_data[i], 0, mode='train')\n",
    "        z_tensor = torch.cat((z_tensor, z_tensor_tmp), 0)\n",
    "        if i % 5 == 0:\n",
    "            print(i, z_tensor.shape)\n",
    "        del z_tensor_tmp\n",
    "\n",
    "    print(z_tensor.shape)\n",
    "    \n",
    "    dz_tensor = z_tensor[2:data_len]\n",
    "    z_tensor = z_tensor[1:data_len-1]\n",
    "    \n",
    "    # calculate sindy and Xi for the data\n",
    "    z = z_tensor.cpu().detach().numpy()\n",
    "    dz = dz_tensor.cpu().detach().numpy()\n",
    "\n",
    "    Theta = torch.from_numpy(sindy.sindy_library(z, gl_poly_order, include_sine=gl_include_sine_param))\n",
    "    Xi = torch.from_numpy(sindy.sindy_fit(Theta, dz, gl_threshold_sindy))\n",
    "    \n",
    "    return Xi\n",
    "\n",
    "def matrixToNorm(x, offset=0, factor=0.95):\n",
    "    x = (x - x.min() + offset) / x.max() * factor\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## configurations #####################################\n",
    "gl_epoch = 4200\n",
    "gl_zDim = 3\n",
    "gl_poly_order = 5\n",
    "gl_lr_rate = 1e-05\n",
    "gl_include_sine_param = False\n",
    "gl_threshold_sindy = 0.05\n",
    "gl_batchSize = 16\n",
    "gl_divideBatch = 4        # take int(batchSize/divideBatch) Frames pro prediction\n",
    "\n",
    "\n",
    "path_folder = 'results/v5_3_z'+str(gl_zDim)+'_Cu/'\n",
    "path_figures = 'figures/v5_3_z'+str(gl_zDim)+'_Cu/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data and the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loading model\n",
    "to_load = path_folder+'Ae_'+str(gl_epoch)+'epoch_bs16_lr'+str(gl_lr_rate)+'_z'+str(gl_zDim)+'_sindt'+str(gl_threshold_sindy)+'_poly'+str(gl_poly_order)+'_4PFrame.pt'\n",
    "autoencoder = torch.load(to_load)\n",
    "autoencoder = autoencoder.cpu()\n",
    "\n",
    "# load a train data\n",
    "path_folder_data = path_folder+'data/'\n",
    "train_data = torch.load(path_folder_data + 'train_data.pt')\n",
    "print('train data: ', len(train_data), len(train_data[0]), len(train_data[0][0]), len(train_data[0][0][0]), len(train_data[0][0][0][0]))\n",
    "print('train data reading done!')\n",
    "\n",
    "# load a validation data\n",
    "validation_data = torch.load(path_folder_data + 'validation_data.pt')\n",
    "print('validation data: ', len(validation_data), len(validation_data[0]), len(validation_data[0][0]), len(validation_data[0][0][0]), len(validation_data[0][0][0][0]))\n",
    "print('validation data reading done!')\n",
    "\n",
    "# loading test data\n",
    "test_data = torch.load(path_folder_data + 'test_data.pt')\n",
    "print('test data: ', len(test_data), len(test_data[0]), len(test_data[0][0]), len(test_data[0][0][0]), len(test_data[0][0][0][0]))\n",
    "print('test data reading done!')\n",
    "\n",
    "# load Xi\n",
    "Xi = torch.load(path_folder + 'Xi_'+str(gl_epoch)+'epoch_bs16_lr'+str(gl_lr_rate)+'_z'+str(gl_zDim)+'_sindt'+str(gl_threshold_sindy)+'_poly'+str(gl_poly_order)+'_4PFrame.pt')\n",
    "print('Xi loaded succesfully!')\n",
    "print(Xi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting images of autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "whichData = 'train_data'\n",
    "if whichData == 'train_data':\n",
    "    data = train_data\n",
    "elif whichData == 'validation_data':\n",
    "    data = validation_data\n",
    "elif whichData == 'test_data':\n",
    "    data = test_data\n",
    "\n",
    "    \n",
    "# plot random auto encoder result\n",
    "plt.show()\n",
    "print('random picture from '+str(whichData))\n",
    "randPlace = random.randint(0, len(data)-1)\n",
    "z_tensor, recon_tensor = autoencoder(data[randPlace], 0, mode='train')\n",
    "# plot sindy result\n",
    "for nbImag in range(len(recon_tensor)):\n",
    "    plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(data[randPlace][nbImag].permute(1,2,0).detach().numpy())\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(recon_tensor[nbImag].permute(1,2,0).detach().numpy())\n",
    "plt.savefig(path_figures+'autoencoder_'+str(whichData)+'_'+str(gl_epoch)+'epoch_4PFrame.png', transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting images for the first glance of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "whichData = 'train_data'\n",
    "if whichData == 'train_data':\n",
    "    data = train_data\n",
    "elif whichData == 'validation_data':\n",
    "    data = validation_data\n",
    "elif whichData == 'test_data':\n",
    "    data = test_data\n",
    "\n",
    "nbrSteps = len(data) -10   # number of steps, validation_data: len(data) \n",
    "\n",
    "    \n",
    "z_tensor, recon_tensor = autoencoder(data[0], 0, mode='train')\n",
    "z = z_tensor.cpu()\n",
    "for step in range(nbrSteps):\n",
    "    print('prediction at step', step)\n",
    "    plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(data[step][0].permute(1,2,0).detach().numpy())\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(recon_tensor[0].permute(1,2,0).detach().numpy())\n",
    "    # SINDy prediction\n",
    "    z_last = z[len(z)-int(gl_batchSize/gl_divideBatch)-1:len(z)-1]\n",
    "    dz_predict = torch.empty((0, gl_zDim))\n",
    "    for i in range(gl_divideBatch):\n",
    "        Theta = torch.from_numpy(sindy.sindy_library(z_last.cpu().detach().numpy(), gl_poly_order, include_sine=gl_include_sine_param))\n",
    "        z_last = torch.matmul(Theta, Xi).float().cpu()\n",
    "        dz_predict = torch.cat((dz_predict, z_last.cpu()))\n",
    "    _, recon_tensor = autoencoder(0, dz_predict, mode='test')\n",
    "    z = dz_predict.cpu()\n",
    "    # that savefig works\n",
    "    if step != nbrSteps-1:\n",
    "        plt.show()\n",
    "\n",
    "plt.savefig(path_figures+'prediction'+str(nbrSteps)+'Steps_'+str(whichData)+'_'+str(gl_epoch)+'epoch_4PFrame.png', transparent=True, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting in z dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "whichData = 'train_data'\n",
    "if whichData == 'train_data':\n",
    "    data = train_data\n",
    "elif whichData == 'validation_data':\n",
    "    data = validation_data\n",
    "elif whichData == 'test_data':\n",
    "    data = test_data\n",
    "    \n",
    "ChooseLength = len(data)  # len(data)\n",
    "ChoosePredictionLength = len(data) + 5     # len(data)\n",
    "batch_size = 16\n",
    "\n",
    "# compute true z\n",
    "z_true = np.empty((ChooseLength*batch_size, gl_zDim))\n",
    "for index in range(0, ChooseLength):\n",
    "    if index >= len(data):\n",
    "        break\n",
    "    z_tensor, recon_tensor = autoencoder(data[index], 0, mode='train')\n",
    "    z_true[index*batch_size:(index+1)*batch_size][:] = z_tensor.cpu().detach().numpy()\n",
    "    if index % 5 == 0: print(index)\n",
    "\n",
    "print('z_true dimension', z_true.shape)\n",
    "    \n",
    "# print graph(s) for z_true\n",
    "for graph in range(z_true.shape[1]):\n",
    "    plt.figure(graph)\n",
    "    x = np.linspace(0, z_true.shape[0], z_true.shape[0])\n",
    "    y = z_true[:,graph]\n",
    "    plt.plot(x, y, color='black', label='z true')\n",
    "\n",
    "# compute sindy z predition based on first one\n",
    "z_tensor, recon_tensor = autoencoder(data[0], 0, mode='train')\n",
    "z = z_tensor.cpu()\n",
    "z_sindy = np.empty((ChoosePredictionLength*batch_size, gl_zDim))\n",
    "z_sindyUnsmooth = np.empty((ChoosePredictionLength*batch_size, gl_zDim))\n",
    "z_sindy[0:16] = z.cpu().detach().numpy()\n",
    "for index_s in range(0, ChoosePredictionLength-1):\n",
    "    # SINDy prediction\n",
    "    z_last = z[len(z)-int(gl_batchSize/gl_divideBatch)-1:len(z)-1]\n",
    "    dz_predict = torch.empty((0, gl_zDim))\n",
    "    for i in range(gl_divideBatch):\n",
    "        Theta = torch.from_numpy(sindy.sindy_library(z_last.cpu().detach().numpy(), gl_poly_order, include_sine=gl_include_sine_param))\n",
    "        z_last = torch.matmul(Theta, Xi).float().cpu()\n",
    "        dz_predict = torch.cat((dz_predict, z_last.cpu()))\n",
    "    _, recon_tensor = autoencoder(0, dz_predict, mode='test')\n",
    "    z = dz_predict.cpu()\n",
    "    z_sindy[(index_s+1)*batch_size:(index_s+2)*batch_size] = dz_predict.cpu().detach().numpy()\n",
    "        \n",
    "# print graph(s) for z_sindy\n",
    "for graph in range(z_sindy.shape[1]):\n",
    "    plt.figure(graph)\n",
    "    x = np.linspace(0, z_sindy.shape[0], z_sindy.shape[0])\n",
    "    y = z_sindy[:,graph]\n",
    "    z_sindyUnsmooth[:,graph] = z_sindy[:,graph]              # save unsmoothed signal for later use\n",
    "    plt.plot(x, y, label='z prediction')\n",
    "    # smooth z coordinate plot\n",
    "    z_sindy[:,graph] = savgol_filter(z_sindy[:,graph], 61, 3)\n",
    "    y = z_sindy[:,graph]\n",
    "    plt.plot(x, y, color='red', label='z smoothed')\n",
    "    plt.legend()\n",
    "    plt.savefig(path_figures+'graph_z'+str(graph)+'_'+str(whichData)+'_length'+str(ChooseLength)+'_'+str(gl_epoch)+'epoch_4PFrame.png', transparent=True, bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "del z_true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producing a video with sindy steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test with z_sindy from above\n",
    "batch_size = 16\n",
    "\n",
    "# test model with filtered z coordinates\n",
    "def test(zData):\n",
    "    video_reconstruction = []\n",
    "    # predict videos\n",
    "    for i in range(int(len(zData)/batch_size)):\n",
    "        print(i)\n",
    "        z_tensor = torch.from_numpy(zData[i*batch_size:(i+1)*batch_size,:])\n",
    "        _, recon_tensor = autoencoder(0, z_tensor.float(), mode='test')\n",
    "        video_reconstruction.append(recon_tensor)        \n",
    "            \n",
    "    return video_reconstruction\n",
    "\n",
    "\n",
    "video_output = test(z_sindy)\n",
    "print('prediction done!')\n",
    "\n",
    "#del test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test with raw data\n",
    "whichData = 'train_data'\n",
    "if whichData == 'train_data':\n",
    "    data = train_data\n",
    "elif whichData == 'validation_data':\n",
    "    data = validation_data\n",
    "elif whichData == 'test_data':\n",
    "    data = test_data\n",
    "    \n",
    "until = 15\n",
    "\n",
    "# test model from data\n",
    "def test(data):\n",
    "    video_reconstruction = []\n",
    "    # predict videos\n",
    "    # first step encode first batch\n",
    "    img = data[0]\n",
    "    z_tensor, recon_tensor = autoencoder(img, 0, mode='train')\n",
    "    \n",
    "    # predict the future using only sindy model, new video starts always at position vid_nbr * until\n",
    "    for i in range(0, until):\n",
    "        if i % 5 == 0: print('pred', i)\n",
    "        video_reconstruction.append(recon_tensor)\n",
    "        dz_tensor = calculateSindy(z_tensor, Xi, gl_poly_order, gl_include_sine_param)\n",
    "        _, recon_tensor = autoencoder(0, dz_tensor, mode='test')\n",
    "        z_tensor = dz_tensor\n",
    "            \n",
    "    return video_reconstruction\n",
    "\n",
    "\n",
    "video_output = test(test_data)\n",
    "print('prediction done!')\n",
    "\n",
    "#del test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make videos\n",
    "frame_width = len(video_output[0][0][0][0])\n",
    "frame_height = len(video_output[0][0][0])\n",
    "fps = 25.0\n",
    "video_output = video_output\n",
    "#fourcc = cv2.VideoWriter_fourcc('I','4','2','0')\n",
    "#fourcc = cv2.VideoWriter_fourcc('P','I','M','1')\n",
    "#fourcc = cv2.VideoWriter_fourcc('X','V','I','D')\n",
    "fourcc = cv2.VideoWriter_fourcc('D','I','V','3')\n",
    "#fourcc = cv2.VideoWriter_fourcc('F','L','V','1')\n",
    "# write different videos\n",
    "#fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "#fourcc = cv2.VideoWriter_fourcc('D','I','V','3')\n",
    "#fourcc = cv2.VideoWriter_fourcc('F','M','P','4')\n",
    "out1 = cv2.VideoWriter(path_figures+'prediction_smoothed_'+str(whichData)+'_'+str(gl_epoch)+'epoch_PFrame.avi', fourcc, fps, (frame_width,frame_height))\n",
    "#out2 = cv2.VideoWriter('video2.mov',cv2.VideoWriter_fourcc('M','J','P','G'), fps, (frame_width,frame_height))\n",
    "\n",
    "\n",
    "print('output video', len(video_output), len(video_output[0]), len(video_output[0][0]), len(video_output[0][0][0]), len(video_output[0][0][0][0]))\n",
    "\n",
    "# undo batch structure\n",
    "videoProcessing = []\n",
    "count = -1\n",
    "for img in range(0, len(video_output)*len(video_output[0])):\n",
    "    imgIn_batch = img % batch_size\n",
    "    # new batch\n",
    "    if imgIn_batch == 0:\n",
    "        count += 1\n",
    "    img_toAppend = video_output[count][imgIn_batch]\n",
    "    videoProcessing.append(img_toAppend)\n",
    "        \n",
    "#del video_output\n",
    "print('video currently procession', len(videoProcessing), len(videoProcessing[0]), len(videoProcessing[0][0]), len(videoProcessing[0][0][0]))\n",
    "    \n",
    "for img in range(0,len(videoProcessing)):\n",
    "    frame_local = np.transpose(videoProcessing[img].detach().numpy(), [1,2,0])\n",
    "    frame_local = cv2.cvtColor(frame_local, cv2.COLOR_RGB2BGR)\n",
    "    # print(frame_local) --> seems unstable, not a number and doesn't save it as a video\n",
    "    out1.write(frame_local)\n",
    "    # show video\n",
    "    cv2.imshow('Frame',frame_local)\n",
    "    \n",
    "    # wait at the beginning\n",
    "    if img == 0:\n",
    "        print('stopped video in frame',img)\n",
    "        while(True):\n",
    "            if cv2.waitKey(25) & 0xFF == ord('e'):\n",
    "                break\n",
    "\n",
    "    # Press Q on keyboard to  exit\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q') and img >= 10:\n",
    "        break\n",
    "    \n",
    "    # Press w on keyboard to wait\n",
    "    if cv2.waitKey(25) & 0xFF == ord('w'):\n",
    "        print('stopped video in frame', img)\n",
    "        while(True):\n",
    "            if cv2.waitKey(25) & 0xFF == ord('e'):\n",
    "                break\n",
    "            \n",
    "\n",
    "# When everything done, release the video capture and video write objects\n",
    "out1.release()\n",
    "\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print('finished prediction video output!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### some more things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xi = constructXi(train_data, gl_zDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
